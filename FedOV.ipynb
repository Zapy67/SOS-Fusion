{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone http://github.com/wizard1203/FuseFL","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!git clone https://github.com/Xtra-Computing/FedOV","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T19:17:32.483633Z","iopub.execute_input":"2025-12-27T19:17:32.484452Z","iopub.status.idle":"2025-12-27T19:17:32.997840Z","shell.execute_reply.started":"2025-12-27T19:17:32.484416Z","shell.execute_reply":"2025-12-27T19:17:32.997184Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'FedOV'...\nremote: Enumerating objects: 175, done.\u001b[K\nremote: Counting objects: 100% (158/158), done.\u001b[K\nremote: Compressing objects: 100% (68/68), done.\u001b[K\nremote: Total 175 (delta 90), reused 150 (delta 86), pack-reused 17 (from 1)\u001b[K\nReceiving objects: 100% (175/175), 95.03 KiB | 5.94 MiB/s, done.\nResolving deltas: 100% (92/92), done.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!ls","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T19:17:34.165688Z","iopub.execute_input":"2025-12-27T19:17:34.166522Z","iopub.status.idle":"2025-12-27T19:17:34.284352Z","shell.execute_reply.started":"2025-12-27T19:17:34.166487Z","shell.execute_reply":"2025-12-27T19:17:34.283500Z"}},"outputs":[{"name":"stdout","text":"FedOV  FuseFL\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"%%writefile FuseFL/alg_train.py\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# Python version: 3.6\nimport argparse\nimport copy\nimport os\nimport shutil\nimport sys\nimport warnings\nimport torchvision.models as models\nimport numpy as np\nfrom tqdm import tqdm\nimport pdb\nimport logging\nimport time\n\n\nfrom helpers.datasets import partition_data, load_data, get_image_size, get_num_of_labels\nfrom helpers.utils import get_dataset, average_weights, DatasetSplit, BackdoorDS, KLDiv, setup_seed, test, progressive_test\nfrom helpers.exp_path import ExpTool\n\n\nfrom models.generator import Generator\nfrom models.nets import CNNCifar, CNNMnist, CNNCifar100\nfrom models.pnn import PNN\nfrom models.pnn_cnn import PNN_CNN, pnn_resnet18, pnn_resnet50\n\nfrom models.fl_pnn import Federated_PNN\nfrom models.fl_pnn_cnn import Federated_PNN_CNN, fl_pnn_resnet18, fl_pnn_resnet50\nfrom models.mlp import MLP\nfrom models.fl_exnn import (MLP_Block, CNN_Block,\n    merge_layer, Federated_EXNN, Federated_EXNNLayer_global, Federated_EXNNLayer_local,\n    fl_exnn_resnet18, fl_exnn_resnet50, \n)\nfrom models.seq_model import Sequential_SplitNN, ReconMIEstimator\n\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nimport torch.nn.functional as F\n\nfrom models.resnet import resnet18, resnet50, get_res18_out_channels\nfrom models.vit import deit_tiny_patch16_224\nimport wandb\nfrom models.configs import Split_Configs, EXNN_Split_Configs\n\nwarnings.filterwarnings('ignore')\nupsample = torch.nn.Upsample(mode='nearest', scale_factor=7)\n\nfrom locals.fedavg import LocalUpdate\nfrom locals.fl_progressive import FedPnnLocalUpdate\nfrom locals.progressive import PnnLocalUpdate\nfrom locals.fl_expandable import FedEXNNLocalUpdate\nfrom locals.ccvr import (compute_classes_mean_cov, generate_virtual_representation,\n    calibrate_classifier, get_means_covs_from_client)\n\nfrom utils import seq_map_values, batch, accuracy, show_model_layers\n\n\n\ndef obtain_projection_head(before_cls_feature_num, contrastive_projection_dim):\n    projector = nn.Sequential(\n        nn.Linear(before_cls_feature_num, before_cls_feature_num, bias=False),\n        nn.ReLU(),\n        nn.Linear(before_cls_feature_num, contrastive_projection_dim, bias=False),\n    )\n    return projector\n\n\nclass Ensemble(torch.nn.Module):\n    def __init__(self, model_list):\n        super(Ensemble, self).__init__()\n        self.models = model_list\n\n    def to(self, device):\n        for model in self.models:\n            model.to(device)\n\n\n    def forward(self, x):\n        logits_total = 0\n        for i in range(len(self.models)):\n            logits = self.models[i](x)\n            logits_total += logits\n        logits_e = logits_total / len(self.models)\n\n        return logits_e\n\n\ndef pretrain(args, device, logger, train_dataset, test_dataset, \n            train_user_groups, train_data_cls_counts, \n            test_user_groups, test_data_cls_counts,\n            global_test_loader, global_model, out_channels):\n\n    bst_acc = -1\n    description = \"inference acc={:.4f}% loss={:.2f}, best_acc = {:.2f}%\"\n    users = []\n    locals = []\n\n    before_cls_feature_num = out_channels[-1]\n    backdoor_test_loader = None\n    if args.backdoor_train: \n        backdoor_test_loader = DataLoader(BackdoorDS(test_dataset, args.backdoor_size, mode=\"random\"),\n                                    batch_size=256, shuffle=False, num_workers=4)\n\n    # ===============================================\n    for idx in range(args.num_users):\n        logger.info(\"client {}\".format(idx))\n        users.append(\"client_{}\".format(idx))\n        if args.backdoor_train and idx < args.backdoor_n_clients:\n            local_update = LocalUpdate(args, train_dataset, test_dataset, global_test_loader,\n                train_user_groups[idx], test_user_groups[idx], copy.deepcopy(global_model), backdoor_train=True)\n        else:\n            local_update = LocalUpdate(args, train_dataset, test_dataset, global_test_loader,\n                train_user_groups[idx], test_user_groups[idx], copy.deepcopy(global_model))\n        locals.append(local_update)\n        if args.contrastive_train:\n            # We use a MLP with one hidden layer to obtain z_i = g(h_i) = W(2)σ(W(1)h_i) where σ is a ReLU non-linearity.\n            projector = obtain_projection_head(before_cls_feature_num, args.contrastive_projection_dim)\n            local_update.add_CL_head(projector)\n\n    train_time = 0\n    total_epoch = 0\n    for epoch in range(args.local_ep):\n        start_time = time.time()\n        local_weights = []\n        train_losses = []\n        acc_list = []\n        pfl_acc_list = []\n        training_pfl_acc_list = []\n        if epoch % 10 == 0 or epoch < 10 or epoch == args.local_ep - 1:\n            if_test = True\n        else:\n            if_test = False\n        if_test = True\n        for idx in range(args.num_users):\n            # not load global model, for one-shot communication...\n            w, avg_train_loss, global_acc, pfl_acc, train_pfl_acc = locals[idx].update_weights(idx, 1, device, if_test=if_test)\n            acc_list.append(global_acc)\n            train_losses.append(avg_train_loss)\n            pfl_acc_list.append(pfl_acc)\n            training_pfl_acc_list.append(train_pfl_acc)\n            # local_weights.append(copy.deepcopy(w))\n            local_weights.append(w)\n\n        total_epoch += args.local_ep\n\n        avg_train_loss = np.mean(train_losses)\n        train_time += time.time() - start_time\n\n        global_weights = average_weights(local_weights)\n        global_model.load_state_dict(global_weights)\n        model_list = []\n        for i in range(len(local_weights)):\n            net = copy.deepcopy(global_model)\n            net.load_state_dict(local_weights[i])\n            model_list.append(net)\n        ensemble_model = Ensemble(model_list)\n        if if_test:\n            result_dict = {}\n            for idx in range(args.num_users):\n                result_dict[\"client_{}_acc\".format(users[idx])] = acc_list[idx]\n                result_dict[\"pfl_acc_on_{}\".format(users[idx])] = pfl_acc_list[idx]\n                result_dict[\"pfl_training_acc_on_{}\".format(users[idx])] = training_pfl_acc_list[idx]\n\n            ExpTool.record(result_dict)\n            test_acc, test_loss = test(global_model, global_test_loader, device)\n            logger.info(f\"avg acc: {test_acc}\")\n\n            ensemble_acc, ensemble_loss = test(ensemble_model, global_test_loader, device)\n            if args.backdoor_train:\n                ensemble_backdoor_acc, ensemble_backdoor_loss = test(ensemble_model, backdoor_test_loader, device)\n                logger.info(f\"ensemble_backdoor_acc: {ensemble_backdoor_acc}\")\n                ExpTool.record({\"ensemble_backdoor_acc\": ensemble_backdoor_acc,\n                                \"ensemble_backdoor_loss\": ensemble_backdoor_loss})\n\n            logger.info(f\"ensemble acc: {ensemble_acc}\")\n            ExpTool.record({\"comm_round\": 0, \"local_epoch\": total_epoch, \"train_loss\": avg_train_loss,\n                            \"test_acc\": test_acc, \"ensemble_acc\": ensemble_acc, \"train_time\": train_time})\n            ExpTool.upload()\n\n    count_para = 0\n    for local_weight in local_weights:\n        # for key, value in local_weight.named_parameters():\n        for key, value in local_weight.items():\n            count_para += value.numel()\n    summary_dict = {\"count_paras\": count_para}\n    logger.info(f\"summary_dict: {summary_dict}\")\n    ExpTool.summary(summary_dict)\n    # ===============================================\n    if not args.checkpoint == \"no\":\n        ExpTool.save_pickle(local_weights, args.checkpoint, exp_dir=True)\n    # ExpTool.load_pickle\n    # torch.save(local_weights, '{}_{}clients_{}.pkl'.format(args.dataset, args.num_users, args.alpha))\n    return global_model, global_weights, local_weights, model_list\n\n\n\n\n\n\ndef progressive(args, device, logger, train_dataset, test_dataset, \n            train_user_groups, train_data_cls_counts, \n            test_user_groups, test_data_cls_counts,\n            global_test_loader, global_model, out_channels):\n\n    bst_acc = -1\n    description = \"inference acc={:.4f}% loss={:.2f}, best_acc = {:.2f}%\"\n    users = []\n    locals = []\n\n    # ===============================================\n    for idx in range(args.num_users):\n        logger.info(\"client {}\".format(idx))\n        users.append(\"client_{}\".format(idx))\n        local_update = PnnLocalUpdate(args, train_dataset, test_dataset, global_test_loader,\n                            train_user_groups[idx], test_user_groups[idx])\n        locals.append(local_update)\n\n    global_model.train()\n    global_model.to(device)\n    # Now, there is no local weights in progressive FL, because the model is increasing...\n    training_pfl_acc_list = []\n    train_losses = []\n    train_time = 0\n    for idx in range(args.num_users):\n        start_time = time.time()\n        # not load global model, for one-shot communication...\n        _, avg_train_loss, _, train_pfl_acc = locals[idx].update_weights(idx, args.local_ep, global_model, device, if_test=True)\n        training_pfl_acc_list.append(train_pfl_acc)\n        train_losses.append(avg_train_loss)\n        train_time += time.time() - start_time\n\n    avg_train_loss = np.mean(train_losses)\n\n    # Test global and ensemble model\n    # NOTE: global weights need not to be averaged\n    num_total_corrects = 0\n    num_total = 0\n    pfl_accs = []\n    for idx in range(args.num_users):\n        local = locals[idx]\n        num_total += len(local.global_test_loader.dataset)\n        pfl_acc, pfl_test_loss, correct = progressive_test(global_model, local.global_test_loader, idx, device)\n        pfl_accs.append(pfl_acc)\n        num_total_corrects += correct\n    test_acc = 100. * num_total_corrects / num_total\n\n    result_dict = {}\n    for idx in range(args.num_users):\n        result_dict[\"pfl_acc_on_{}\".format(users[idx])] = pfl_accs[idx]\n        result_dict[\"pfl_training_acc_on_{}\".format(users[idx])] = training_pfl_acc_list[idx]\n\n    logger.info(f\"pfl_accs: {pfl_accs}\")\n    logger.info(f\"training_pfl_acc_list:{training_pfl_acc_list}\")\n    logger.info(f\"test_acc:{test_acc}\")\n\n    ExpTool.record(result_dict)\n    logger.info(\"avg acc:\")\n    ExpTool.record({\"comm_round\": 0, \"local_epoch\": args.local_ep, \"train_loss\": avg_train_loss,\n                    \"test_acc\": test_acc, \"train_time\": train_time})\n    ExpTool.upload()\n\n    count_para = 0\n    for key, value in global_model.named_parameters():\n        count_para += value.numel()\n    summary_dict = {\"count_paras\": count_para}\n    logger.info(f\"summary_dict: {summary_dict}\")\n    ExpTool.summary(summary_dict)\n\n    # ===============================================\n    if not args.checkpoint == \"no\":\n        ExpTool.save_pickle(global_model.cpu().state_dict(), args.checkpoint, exp_dir=True)\n    # torch.save(global_model.cpu().state_dict(), '{}_{}_{}clients_{}.pkl'.format(args.type, args.dataset, args.num_users, args.alpha))\n\n\ndef fed_progressive(args, device, logger, train_dataset, test_dataset, \n            train_user_groups, train_data_cls_counts, \n            test_user_groups, test_data_cls_counts,\n            global_test_loader, global_model, out_channels):\n\n    bst_acc = -1\n    description = \"inference acc={:.4f}% loss={:.2f}, best_acc = {:.2f}%\"\n    users = []\n    locals = []\n    for idx in range(args.num_users):\n        logger.info(\"client {}\".format(idx))\n        users.append(\"client_{}\".format(idx))\n        local_update = FedPnnLocalUpdate(args, train_dataset, test_dataset, global_test_loader,\n                            train_user_groups[idx], test_user_groups[idx])\n        locals.append(local_update)\n\n    global_model.train()\n    global_model.to(device)\n    # Now, there is no local weights in progressive FL, because the model is increasing...\n    training_pfl_acc_list = []\n    train_losses = []\n    train_time = 0\n    for idx in range(args.num_users):\n        # not load global model, for one-shot communication...\n        start_time = time.time()\n        _, avg_train_loss, _, train_pfl_acc = locals[idx].update_weights(idx, args.local_ep, global_model, device, if_test=True)\n        training_pfl_acc_list.append(train_pfl_acc)\n        train_losses.append(avg_train_loss)\n        train_time += time.time() - start_time\n\n    avg_train_loss = np.mean(train_losses)\n\n    # Test global and ensemble model\n    # NOTE: global weights need not to be averaged\n    logger.info(\"avg acc:\")\n    test_acc, test_loss = test(global_model, global_test_loader, device)\n    pfl_accs = []\n\n    result_dict = {}\n    for idx in range(args.num_users):\n        result_dict[\"pfl_training_acc_on_{}\".format(users[idx])] = training_pfl_acc_list[idx]\n        local_test_acc, _ = test(global_model, locals[idx].test_loader, device)\n        result_dict[\"pfl_acc_on_{}\".format(users[idx])] = local_test_acc\n        pfl_accs.append(local_test_acc)\n\n    logger.info(f\"pfl_accs: {pfl_accs}\")\n    logger.info(f\"training_pfl_acc_list:{training_pfl_acc_list}\")\n    logger.info(f\"test_acc:{test_acc}\")\n\n    ExpTool.record(result_dict)\n    logger.info(\"avg acc:\")\n    ExpTool.record({\"comm_round\": 0, \"local_epoch\": args.local_ep, \"train_loss\": avg_train_loss,\n                    \"test_acc\": test_acc, \"train_time\": train_time})\n    ExpTool.upload()\n    count_para = 0\n    for key, value in global_model.named_parameters():\n        count_para += value.numel()\n    summary_dict = {\"count_paras\": count_para}\n    logger.info(f\"summary_dict: {summary_dict}\")\n    ExpTool.summary(summary_dict)\n\n    # ===============================================\n    if not args.checkpoint == \"no\":\n        ExpTool.save_pickle(global_model.cpu().state_dict(), args.checkpoint, exp_dir=True)\n    # torch.save(global_model.cpu().state_dict(), '{}_{}_{}clients_{}.pkl'.format(args.type, args.dataset, args.num_users, args.alpha))\n\n\n\ndef init_fedexnn_merged(args, split_modules, out_channels):\n    users = []\n    local_FedEXNN_models = {}\n    split_config = EXNN_Split_Configs[args.model][args.fedexnn_split_num]\n    num_of_classes = get_num_of_labels(args.dataset)\n\n    for idx in range(args.num_users):\n        split_local_layers = []\n        for layer_idx, layer in enumerate(split_modules):\n            EXNNLayer_local = Federated_EXNNLayer_local(layer_idx=layer_idx,\n                local_layer=copy.deepcopy(layer),\n                client_idx=idx,\n                adapter=args.fedexnn_adapter,\n                fedexnn_self_dropout=args.fedexnn_self_dropout)\n            split_local_layers.append(EXNNLayer_local)\n        init_model = Federated_EXNN(\n            args,\n            idx,\n            split_local_layers=split_local_layers,\n            num_of_classes=num_of_classes,\n            fedexnn_classifer=args.fedexnn_classifer)\n        local_FedEXNN_models[idx] = init_model\n\n    for idx in range(args.fedexnn_split_num):\n        layer_idx = idx\n        federated_EXNNLayer_global = merge_layer(local_FedEXNN_models, layer_idx)\n        federated_EXNNLayer_global.freeze()\n        # split_local_layers[layer_idx] = federated_EXNNLayer_global\n        for client_idx in range(args.num_users):\n            local_FedEXNN_models[client_idx].adaptation(\n                layer_idx, federated_EXNNLayer_global)\n            if layer_idx < len(split_config):\n                actual_layer_index = split_config[layer_idx]\n                local_FedEXNN_models[client_idx].add_local_layer_adaptor(layer_idx+1,\n                    in_channels=out_channels[actual_layer_index]*args.num_users,\n                    out_channels=out_channels[actual_layer_index])\n    return local_FedEXNN_models[0]\n\n\n\ndef fed_expandable(args, device, logger, train_dataset, test_dataset, \n            train_user_groups, train_data_cls_counts, \n            test_user_groups, test_data_cls_counts,\n            global_test_loader, split_modules, out_channels):\n\n    bst_acc = -1\n    description = \"inference acc={:.4f}% loss={:.2f}, best_acc = {:.2f}%\"\n    users = []\n    locals = []\n    split_config = EXNN_Split_Configs[args.model][args.fedexnn_split_num]\n    num_of_classes = get_num_of_labels(args.dataset) + 1 #over here\n\n    before_cls_feature_num = out_channels[-1]\n    backdoor_test_loader = None\n    if args.backdoor_train: \n        backdoor_test_loader = DataLoader(BackdoorDS(test_dataset, args.backdoor_size, mode=\"random\"),\n                                    batch_size=256, shuffle=False, num_workers=4)\n\n    local_FedEXNN_models = {}\n    for idx in range(args.num_users):\n        logger.info(\"client {}\".format(idx))\n        users.append(\"client_{}\".format(idx))\n        # split_local_layers = copy.deepcopy(split_modules)\n        split_local_layers = []\n        for layer_idx, layer in enumerate(split_modules):\n            EXNNLayer_local = Federated_EXNNLayer_local(layer_idx=layer_idx,\n                local_layer=copy.deepcopy(layer),\n                client_idx=idx,\n                adapter=args.fedexnn_adapter,\n                fedexnn_self_dropout=args.fedexnn_self_dropout)\n            split_local_layers.append(EXNNLayer_local)\n        init_model = Federated_EXNN(\n            args,\n            idx,\n            split_local_layers=split_local_layers,\n            num_of_classes=num_of_classes,\n            fedexnn_classifer=args.fedexnn_classifer)\n        if args.debug_show_exnn_id:\n            logging.info(f\"==========Checking local layer IDs ================\")\n            logging.info(f\"==========Client:{idx}, split_local_layers :{id(split_local_layers)} ================\")\n            for layer_idx, layer in enumerate(split_local_layers):\n                logging.info(f\"==========Client:{idx}, layer_idx{layer_idx} :{id(layer)} ================\")\n            logging.info(f\"==========Client:{idx}, init_model :{id(init_model)} ================\")\n\n        local_FedEXNN_models[idx] = init_model\n        if args.backdoor_train and idx < args.backdoor_n_clients:\n            local_update = FedEXNNLocalUpdate(args, train_dataset, test_dataset, global_test_loader,\n                                train_user_groups[idx], test_user_groups[idx], backdoor_train=True)\n        else:\n            local_update = FedEXNNLocalUpdate(args, train_dataset, test_dataset, global_test_loader,\n                                train_user_groups[idx], test_user_groups[idx])\n        locals.append(local_update)\n        if args.contrastive_train:\n            # We use a MLP with one hidden layer to obtain z_i = g(h_i) = W(2)σ(W(1)h_i) where σ is a ReLU non-linearity.\n            projector = obtain_projection_head(before_cls_feature_num, args.contrastive_projection_dim)\n            local_update.add_CL_head(projector)\n\n\n    # Train and fuse split layers\n    count_para = 0\n    # if args.debug:\n    # show_model_layers(init_model)\n    for key, value in init_model.named_parameters():\n        count_para += value.numel()\n    logger.info(f\"init_model has count_para: {count_para}\")\n\n    for idx in range(args.fedexnn_split_num):\n        pfl_acc_list = []\n        training_pfl_acc_list = []\n        train_losses = []\n        result_dict = {}\n\n        for client_idx in range(args.num_users):\n            # not load global model, for one-shot communication...\n            _, train_loss, _, pfl_acc, train_pfl_acc = locals[client_idx].update_weights(\n                        client_idx, args.local_ep, local_FedEXNN_models[client_idx], device, if_test=True)\n            pfl_acc_list.append(pfl_acc)\n            training_pfl_acc_list.append(train_pfl_acc)\n            train_losses.append(train_loss)\n            result_dict[\"pfl_acc_on_{}\".format(users[client_idx])] = pfl_acc\n            result_dict[\"pfl_training_acc_on_{}\".format(users[client_idx])] = training_pfl_acc_list[client_idx]\n        avg_train_loss = np.mean(train_losses)\n        logger.info(f\"test_pfl_acc_list:{pfl_acc_list}\")\n        logger.info(f\"training_pfl_acc_list:{training_pfl_acc_list}\")\n        # logger.info(f\"test_acc:{test_acc}\")\n        # if idx == 0:\n        #     pass\n        # else:\n        layer_idx = idx\n        logger.info(f\"=====Merging Layer : {layer_idx} =====\")\n        federated_EXNNLayer_global = merge_layer(local_FedEXNN_models, layer_idx)\n        federated_EXNNLayer_global.freeze()\n        # split_local_layers[layer_idx] = federated_EXNNLayer_global\n        for client_idx in range(args.num_users):\n            local_FedEXNN_models[client_idx].adaptation(\n                layer_idx, federated_EXNNLayer_global)\n            if args.debug_show_exnn_id:\n                logging.info(f\"==========Checking global layer IDs ================\")\n                model = local_FedEXNN_models[client_idx]\n                logging.info(f\"==========Client:{client_idx}, local_FedEXNN_models.layers[{layer_idx}] : \\\n                            \\n ========== {id(model.layers[layer_idx])} ================\")\n                for sub_client_idx, local_layer, in federated_EXNNLayer_global.local_layers.items():\n                    if hasattr(local_layer, \"adapter_nn\"):\n                        logging.info(f\"==========In global layer Client:{sub_client_idx},  \\\n                            \\n ================In global layer  local_FedEXNN_models.layers[{layer_idx}].adapter_nn: {id(local_layer.adapter_nn)}\")\n            if layer_idx < len(split_config):\n                actual_layer_index = split_config[layer_idx]\n                local_FedEXNN_models[client_idx].add_local_layer_adaptor(layer_idx+1,\n                    in_channels=out_channels[actual_layer_index]*args.num_users,\n                    out_channels=out_channels[actual_layer_index])\n                if args.debug_show_exnn_id:\n                    if hasattr(model.layers[layer_idx+1], \"adapter_nn\"):\n                        logging.info(f\"==========Client:{client_idx},  \\\n                            \\n ================local_FedEXNN_models.layers[{layer_idx+1}].adapter_nn: {id(model.layers[layer_idx+1].adapter_nn)}\")\n            if args.debug_show_exnn_id:\n                measure_model = local_FedEXNN_models[client_idx]\n                try:\n                    if getattr(measure_model.layers[0], \"is_global\", False):\n                        logger.info(f'client_idx: {client_idx} layer0 - model weight: {measure_model.layers[0].local_layers[\"0\"].local_layer._layers[0][0].weight.data.norm()}')\n                    if getattr(measure_model.layers[1], \"is_global\", False):\n                        logger.info(f'client_idx: {client_idx} layer1 - model (is_global)  has attr adapter_nn : {hasattr(measure_model.layers[1].local_layers[str(client_idx)], \"adapter_nn\")}')\n                        logger.info(f'client_idx: {client_idx} layer1 - model (is_global)  weight: {measure_model.layers[1].local_layers[str(client_idx)].adapter_nn.weight.data.norm()}')\n                    else:\n                        logger.info(f'client_idx: {client_idx} layer1 - model (isnot_global) has attr adapter_nn : {hasattr(measure_model.layers[1], \"adapter_nn\")}')\n                        if hasattr(measure_model.layers[1], \"adapter_nn\"):\n                            logger.info(f'client_idx: {client_idx} layer1 - model (isnot_global) weight: {measure_model.layers[1].adapter_nn.weight.data.norm()}')\n                    if not getattr(measure_model.layers[2], \"is_global\", False):\n                        logger.info(f'client_idx: {client_idx} local layer2 - model weight: {measure_model.layers[2].local_layer._layers[1].conv1.weight.data.norm()}')\n                        logger.info(f'client_idx: {client_idx} local layer2 - model weight: {measure_model.layers[2].local_layer._layers[1].conv2.weight.data.norm()}')\n                except:\n                    pass\n        logger.info(f\"=====Finish Merging Layer : {layer_idx} =====\")\n        ExpTool.record(result_dict)\n        logger.info(f\"result_dict: {result_dict}\")\n        ExpTool.record({\"comm_round\": idx, \"local_epoch\": args.local_ep, \"train_loss\": avg_train_loss})\n        ExpTool.upload()\n    if args.debug_show_exnn_id:\n        for client_idx in range(args.num_users):\n            logging.info(f\"==========Checking global layer IDs ================\")\n            model = local_FedEXNN_models[client_idx]\n            for layer_index, layer in enumerate(model.layers):\n                logging.info(f\"==========Client:{client_idx}, local_FedEXNN_models.layers[{layer_idx}] : \\\n                                \\n ========== {id(layer)} ================\")\n\n    for _, model in local_FedEXNN_models.items():\n        model.to(\"cpu\")\n    global_model = local_FedEXNN_models[0]\n    # if args.debug:\n    #     show_model_layers(global_model)\n\n    # Train and fuse classifier\n    if args.fedexnn_classifer == \"avg\":\n        new_classifier_weights = average_weights([\n            local_FedEXNN_model.classifier.cpu().state_dict()  for local_FedEXNN_model in local_FedEXNN_models.values()])\n        new_classifier = list(local_FedEXNN_models.values())[0].classifier\n        new_classifier.load_state_dict(new_classifier_weights)\n\n    elif args.fedexnn_classifer == \"multihead\":\n        new_classifier = [\n            local_FedEXNN_model.classifier  for local_FedEXNN_model in local_FedEXNN_models.values()]\n    else:\n        raise NotImplementedError\n\n    global_model.adaptation_classifier(fedexnn_classifer=args.fedexnn_classifer, new_classifier=new_classifier)\n    # global_model.train()\n    global_model.to(device)\n    # Now, there is no local weights in progressive FL, because the model is increasing...\n    if args.fedexnn_classifer in [\"avg\"] :\n        if args.contrastive_train:\n            # Get the normal dataloader without n views.\n            image_size = get_image_size(args.dataset)\n            _, _, _, _, train_dataset, test_dataset = load_data(\n                image_size, args.dataset, args.datadir)\n            dataloaders = {}\n            for i, local in enumerate(locals):\n                dataloaders[i] = DataLoader(DatasetSplit(train_dataset, train_user_groups[i]),\n                        batch_size=args.local_bs, shuffle=True, num_workers=4, drop_last=False)\n        else:\n            dataloaders = {}\n            for i, local in enumerate(locals):\n                dataloaders[i] = local.train_loader\n        calibrate_classifier(\n            global_model, None, dataloaders, args.num_classes, args.sample_per_class, args.lr, device)\n    elif args.fedexnn_classifer == \"multihead\":\n        pass\n    else:\n        raise NotImplementedError\n    training_pfl_acc_list = []\n\n    # Test global and ensemble model\n    # NOTE: global weights need not to be averaged\n    logger.info(\"avg acc:\")\n    test_acc, test_loss = test(global_model, global_test_loader, device)\n    pfl_accs = []\n\n    result_dict = {}\n    for idx in range(args.num_users):\n        local_test_acc, _ = test(global_model, locals[idx].test_loader, device)\n        result_dict[\"pfl_acc_on_{}\".format(users[idx])] = local_test_acc\n        pfl_accs.append(local_test_acc)\n    if args.backdoor_train:\n        ensemble_backdoor_acc, ensemble_backdoor_loss = test(global_model, backdoor_test_loader, device)\n        logger.info(f\"ensemble_backdoor_acc: {ensemble_backdoor_acc}\")\n        ExpTool.record({\"ensemble_backdoor_acc\": ensemble_backdoor_acc,\n                        \"ensemble_backdoor_loss\": ensemble_backdoor_loss})\n\n    logger.info(f\"pfl_accs: {pfl_accs}\")\n    logger.info(f\"training_pfl_acc_list:{training_pfl_acc_list}\")\n    logger.info(f\"test_acc:{test_acc}\")\n\n    ExpTool.record(result_dict)\n    logger.info(f\"result_dict: {result_dict}\")\n    ExpTool.record({\"comm_round\": args.fedexnn_split_num + 1, \"local_epoch\": args.local_ep, \"train_loss\": avg_train_loss, \"test_acc\": test_acc})\n    ExpTool.upload()\n    count_para = 0\n    for key, value in global_model.named_parameters():\n        count_para += value.numel()\n    summary_dict = {\"count_paras\": count_para}\n    logger.info(f\"global_model's summary_dict: {summary_dict}\")\n    ExpTool.summary(summary_dict)\n\n    # ===============================================\n    if not args.checkpoint == \"no\":\n        ExpTool.save_pickle(global_model.cpu().state_dict(), args.checkpoint, exp_dir=True)\n    # torch.save(global_model.cpu().state_dict(), '{}_{}_{}clients_{}.pkl'.format(args.type, args.dataset, args.num_users, args.alpha))\n    return global_model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T19:17:43.119171Z","iopub.execute_input":"2025-12-27T19:17:43.120041Z","iopub.status.idle":"2025-12-27T19:17:43.136577Z","shell.execute_reply.started":"2025-12-27T19:17:43.120005Z","shell.execute_reply":"2025-12-27T19:17:43.135900Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true},"outputs":[{"name":"stdout","text":"Overwriting FuseFL/alg_train.py\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# %%bash\n\n# cluster_name=localhost\n# dataset=cifar10\n\n# source scripts/setup_env.sh\n# source scripts/path.sh\n\n# gpu=0\n\n# debug=False\n# enable_wandb=True\n\n\n\n# num_users=5\n\n# alpha=0.5\n# checkpoint=weights\n# res_base_width=64\n# checkpoint=no\n# fedexnn_adapter=cnn1x1\n# res_base_width=20\n# fedexnn_split_num=4\n# local_ep=50\n# wandb_entity=cabbagepatch-lahore-university-of-management-sciences\n# model=resnet18\n\n\n# type=fed-expandable\n# source scripts/resetup_env.sh\n\n# fedexnn_classifer=${fedexnn_classifer:-avg}\n\n# python3 -u main.py --main_task=train --type=$type  --gpu $gpu  --debug $debug \\\n# --exp_name ${type}-${dataset}-${model}-nh${num_hidden_features}-c${num_users}-a${alpha}-ep${local_ep}-lr${lr}-clsf${fedexnn_classifer}-adp${fedexnn_adapter}-nxnn${fedexnn_split_num} \\\n# --checkpoint $checkpoint  \\\n# --split_measure_local_module_num 8 \\\n# --fedexnn_classifer  ${fedexnn_classifer} --fedexnn_adapter ${fedexnn_adapter}  --fedexnn_split_num ${fedexnn_split_num} \\\n# --fedexnn_self_dropout $fedexnn_self_dropout --fedexnn_adapter_constrain_beta $fedexnn_adapter_constrain_beta \\\n# --model=$model --mlp_hidden_features=$mlp_hidden_features --cnn_hidden_features $cnn_hidden_features --num_layers $num_layers --res_base_width $res_base_width \\\n# --iid=0 --lr=$lr \\\n# --dataset=${dataset} --datadir $datadir \\\n# --alpha=$alpha --seed=1 --num_users=${num_users} --local_ep=$local_ep \\\n# --wandb_entity ${wandb_entity} --project_name FuseFL --enable_wandb $enable_wandb --wandb_offline False \\\n# --wandb_key '80702ded3cdc00fb5532f8f21e2ebabb3d2b1b22'\n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T19:17:43.581511Z","iopub.execute_input":"2025-12-27T19:17:43.582251Z","iopub.status.idle":"2025-12-27T19:17:43.586282Z","shell.execute_reply.started":"2025-12-27T19:17:43.582217Z","shell.execute_reply":"2025-12-27T19:17:43.585646Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"%%writefile FuseFL/helpers/datasets.py\nimport os\nimport logging\nimport numpy as np\nimport torch\nimport torchvision.transforms as transforms\nfrom torchvision import datasets, transforms\nimport random\n\nfrom .cl_dataset import _get_simclr_pipeline_transform, _get_cl_transform\n\n\ndef get_image_size(dataset):\n    image_size = {\n        \"mnist\": 28,\n        \"fmnist\": 28,\n        \"SVHN\": 32,\n        \"cifar10\": 32,\n        \"cifar100\": 32,\n        \"Tiny-ImageNet-200\": 64,\n    }[dataset]\n    return image_size\n\ndef get_num_of_labels(dataset):\n    num_of_labels = {\n        \"mnist\": 10,\n        \"fmnist\": 10,\n        \"SVHN\": 10,\n        \"cifar10\": 10,\n        \"cifar100\": 100,\n        \"Tiny-ImageNet-200\": 200,\n    }[dataset]\n    return num_of_labels\n\n\ndef load_data(image_size, dataset, datadir, contrastive_train=False, contrastive_n_views=2, **kwargs):\n    # data_dir = '/dataset'\n    data_dir = datadir\n    if contrastive_train:\n        contrastive_transform = _get_cl_transform(size=image_size, n_views=contrastive_n_views)\n\n    if dataset == \"mnist\":\n        if contrastive_train:\n            train_dataset = datasets.MNIST(data_dir, train=True,\n                                        transform=contrastive_transform)\n        else:\n            train_dataset = datasets.MNIST(data_dir, train=True,\n                                        transform=transforms.Compose(\n                                            [transforms.ToTensor()]))\n        test_dataset = datasets.MNIST(data_dir, train=False,\n                                      transform=transforms.Compose([\n                                          transforms.ToTensor(),\n                                      ]))\n    elif dataset == \"fmnist\":\n        if contrastive_train:\n            train_dataset = datasets.FashionMNIST(data_dir, train=True,\n                                                transform=contrastive_transform)\n        else:\n            train_dataset = datasets.FashionMNIST(data_dir, train=True,\n                                                transform=transforms.Compose(\n                                                    [transforms.ToTensor()]))\n        test_dataset = datasets.FashionMNIST(data_dir, train=False,\n                                             transform=transforms.Compose([\n                                                 transforms.ToTensor(),\n                                             ]))\n    elif dataset == \"SVHN\":\n        if contrastive_train:\n            train_dataset = datasets.SVHN(data_dir, split=\"train\",\n                                        transform=contrastive_transform)\n        else:\n            train_dataset = datasets.SVHN(data_dir, split=\"train\",\n                                        transform=transforms.Compose(\n                                            [transforms.ToTensor()]))\n        test_dataset = datasets.SVHN(data_dir, split=\"test\",\n                                     transform=transforms.Compose([\n                                         transforms.ToTensor(),\n                                     ]))\n    elif dataset == \"cifar10\":\n        if contrastive_train:\n            train_dataset = datasets.CIFAR10(data_dir, train=True,download=True,\n                                            transform=contrastive_transform)\n        else:\n            train_dataset = datasets.CIFAR10(data_dir, train=True,download=True,\n                                            transform=transforms.Compose(\n                                                [\n                                                    transforms.RandomCrop(32, padding=4),\n                                                    transforms.RandomHorizontalFlip(),\n                                                    transforms.ToTensor(),\n                                                ]))\n        test_dataset = datasets.CIFAR10(data_dir, train=False,\n                                        transform=transforms.Compose([\n                                            transforms.ToTensor(),\n                                        ]))\n    elif dataset == \"cifar100\":\n        if contrastive_train:\n            train_dataset = datasets.CIFAR100(data_dir, train=True,\n                                            transform=contrastive_transform)\n        else:\n            train_dataset = datasets.CIFAR100(data_dir, train=True,\n                                            transform=transforms.Compose(\n                                                [\n                                                    transforms.RandomCrop(32, padding=4),\n                                                    transforms.RandomHorizontalFlip(),\n                                                    transforms.ToTensor(),\n                                                ]))\n        test_dataset = datasets.CIFAR100(data_dir, train=False,\n                                         transform=transforms.Compose([\n                                             transforms.ToTensor(),\n                                         ]))\n\n    elif dataset == \"Tiny-ImageNet-200\":\n        data_transforms = {\n            'train': transforms.Compose([\n                transforms.RandomRotation(20),\n                transforms.RandomHorizontalFlip(0.5),\n                transforms.ToTensor(),\n            ]),\n            'val': transforms.Compose([\n                transforms.ToTensor(),\n            ]),\n            'test': transforms.Compose([\n                transforms.ToTensor(),\n            ])\n        }\n        if contrastive_train:\n            data_transforms[\"train\"] = contrastive_transform\n        data_dir = \"data/tiny-imagenet-200/\"\n        image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])\n                          for x in ['train', 'val', 'test']}\n        train_dataset = image_datasets['train']\n        test_dataset = image_datasets['val']\n    else:\n        raise NotImplementedError\n    if dataset == \"SVHN\":\n        X_train, y_train = train_dataset.data, train_dataset.labels\n        X_test, y_test = test_dataset.data, test_dataset.labels\n    else:\n        X_train, y_train = train_dataset.data, train_dataset.targets\n        X_test, y_test = test_dataset.data, test_dataset.targets\n    if \"cifar10\" in dataset or dataset == \"SVHN\":\n        X_train = np.array(X_train)\n        y_train = np.array(y_train)\n        X_test = np.array(X_test)\n        y_test = np.array(y_test)\n    else:\n        X_train = X_train.data.numpy()\n        y_train = y_train.data.numpy()\n        X_test = X_test.data.numpy()\n        y_test = y_test.data.numpy()\n\n    return X_train, y_train, X_test, y_test, train_dataset, test_dataset\n\n\n\n\ndef record_net_data_stats(y_train, net_dataidx_map):\n    net_cls_counts = {}\n    global_unq = np.unique(y_train, return_counts=False)\n    # print(f\"global_unq: {global_unq}\")\n    for net_i, dataidx in net_dataidx_map.items():\n        unq, unq_cnt = np.unique(y_train[dataidx], return_counts=True)\n        # print(f\"unq: {unq}, unq_cnt:{unq_cnt}\")\n        tmp = {}\n        for label in global_unq:\n            if label not in unq:\n                tmp[label] = np.array([0])#this is the only change in this file\n            else:\n                # tmp = {unq[i]: unq_cnt[i] for i in range(len(unq))}\n                label_idx = np.where(unq == label)\n                tmp[label] = unq_cnt[label_idx]\n        net_cls_counts[net_i] = tmp\n\n\n    # print('Data statistics: %s' % str(net_cls_counts))\n\n    return net_cls_counts\n\n\ndef partition_data(image_size, dataset, datadir, partition, alpha=0.4, num_users=5, **kwargs):\n    n_parties = num_users\n    X_train, y_train, X_test, y_test, train_dataset, test_dataset = load_data(\n        image_size, dataset, datadir, **kwargs)\n    data_size = y_train.shape[0]\n\n    if partition == \"iid\":\n        idxs = np.random.permutation(data_size)\n        batch_idxs = np.array_split(idxs, n_parties)\n        net_dataidx_map = {i: batch_idxs[i] for i in range(n_parties)}\n\n    elif partition == \"dirichlet\":\n        min_size = 0\n        min_require_size = 10\n        label = np.unique(y_test).shape[0]\n        net_dataidx_map = {}\n\n        while min_size < min_require_size:\n            idx_batch = [[] for _ in range(n_parties)]\n            for k in range(label):\n                idx_k = np.where(y_train == k)[0]\n                np.random.shuffle(idx_k)  # shuffle the label\n                # random [0.5963643 , 0.03712018, 0.04907753, 0.1115522 , 0.2058858 ]\n                proportions = np.random.dirichlet(np.repeat(alpha, n_parties))\n                proportions = np.array(   # 0 or x\n                    [p * (len(idx_j) < data_size / n_parties) for p, idx_j in zip(proportions, idx_batch)])\n                proportions = proportions / proportions.sum()\n                proportions = (np.cumsum(proportions) * len(idx_k)).astype(int)[:-1]\n                idx_batch = [idx_j + idx.tolist() for idx_j, idx in zip(idx_batch, np.split(idx_k, proportions))]\n                min_size = min([len(idx_j) for idx_j in idx_batch])\n\n        for j in range(n_parties):\n            np.random.shuffle(idx_batch[j])\n            net_dataidx_map[j] = idx_batch[j]\n    train_data_cls_counts = record_net_data_stats(y_train, net_dataidx_map)\n\n    test_net_dataidx_map = generate_personalized_data(X_test, y_test, train_data_cls_counts)\n    test_data_cls_counts = record_net_data_stats(y_test, test_net_dataidx_map)\n\n    np_test_cls_counts = np.array([list(item.values()) for item in test_data_cls_counts.values()])\n    # print(\"test_data_cls_counts: \\n\", test_data_cls_counts)\n    # print(\"np_test_cls_counts: \\n\", np_test_cls_counts)\n\n    return train_dataset, test_dataset, net_dataidx_map, train_data_cls_counts, test_net_dataidx_map, test_data_cls_counts\n\n\ndef generate_personalized_data(X_test, y_test, train_data_cls_counts):\n    # train_label = [i.dataset.targets for i in self.train_data_local_dict.values()]\n    # label = np.unique(y_test).shape[0]\n\n    # print(train_label[0].shape)\n    # class_propotion=np.array([[np.sum(y==i) for i in range(num_classes)] for y in train_label])\n    # print(class_propotion)\n    # num_train=np.sum(class_propotion)\n    # num_class=np.sum(class_propotion, axis=0, keepdims=False)\n\n    num_classes = len(np.unique(y_test))\n    n_parties = len(train_data_cls_counts)\n    np_train_cls_counts = np.array([list(item.values()) for item in train_data_cls_counts.values()])\n    num_class=np.sum(np_train_cls_counts, axis=0, keepdims=False)\n\n    # num_class = [0] * n_parties\n    # for i_class in range(num_classes):\n    #     for idx in train_data_cls_counts.keys():\n    #         num_class[i_class] += train_data_cls_counts[idx][i_class]\n\n    # new_loader=list(zip(X, y))\n    # num_test=len(y_test)\n    # min_size=0\n\n    # print(\"train_data_cls_counts: \\n\", train_data_cls_counts)\n    # print(\"np_train_cls_counts: \\n\", np_train_cls_counts)\n    idx_batch = [[] for _ in range(n_parties)]\n    print(\"num_classes: \\n\", num_class)\n\n    for k in range(num_classes):\n        idx_k = np.where(y_test == k)[0]\n        num=len(idx_k)\n        np.random.shuffle(idx_k)\n        k_num=(np.cumsum(np_train_cls_counts[:, k]*1.0/num_class[k])*num).astype(int)[:-1]\n        # print(\"k_num:\", k_num)\n        # print(\"spilt result::::\",np.split(idx_k, k_num))\n        idx_batch=[idx_j + idx.tolist() for idx_j, idx in zip(idx_batch, np.split(idx_k, k_num))]\n    #     print(\"len(idx_batch)\", len(idx_batch))\n    # print(\"[len(idx_j) for idx_j in idx_batch]\", [len(idx_j) for idx_j in idx_batch])\n    # print(\"sum of len(idx_j)\", sum([len(idx_j) for idx_j in idx_batch]))\n    net_dataidx_map = {}\n\n    for j in range(n_parties):\n        np.random.shuffle(idx_batch[j])\n        net_dataidx_map[j] = idx_batch[j]\n    # np.save(f\"result/{self.args.dataset}_{self.args.partition_alpha}alpha_{self.args.client_num_in_total}client_testdata_cls_matrix\", testdata_cls_matrix)\n    return net_dataidx_map\n\n\n\n\n\n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T19:17:45.456962Z","iopub.execute_input":"2025-12-27T19:17:45.457595Z","iopub.status.idle":"2025-12-27T19:17:45.466153Z","shell.execute_reply.started":"2025-12-27T19:17:45.457567Z","shell.execute_reply":"2025-12-27T19:17:45.465375Z"},"jupyter":{"source_hidden":true}},"outputs":[{"name":"stdout","text":"Overwriting FuseFL/helpers/datasets.py\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"!cp FedOV/attack.py FuseFL/locals/\n!cp FedOV/cutpaste.py FuseFL/locals/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T19:17:45.861060Z","iopub.execute_input":"2025-12-27T19:17:45.861723Z","iopub.status.idle":"2025-12-27T19:17:46.095505Z","shell.execute_reply.started":"2025-12-27T19:17:45.861694Z","shell.execute_reply":"2025-12-27T19:17:46.094823Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"# RUN FROM HERE","metadata":{}},{"cell_type":"code","source":"cd FuseFL","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T19:17:47.543086Z","iopub.execute_input":"2025-12-27T19:17:47.543877Z","iopub.status.idle":"2025-12-27T19:17:47.549384Z","shell.execute_reply.started":"2025-12-27T19:17:47.543845Z","shell.execute_reply":"2025-12-27T19:17:47.548802Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/FuseFL\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"%%writefile main.py\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# Python version: 3.6\nimport argparse\nimport copy\nfrom copy import deepcopy\nimport os\nimport math\nimport shutil\nimport sys\nimport warnings\nimport torchvision.models as models\nimport numpy as np\nfrom tqdm import tqdm\nimport pdb\nimport logging\nimport time\n\nimport torch.nn as nn\n\nsys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), \"../../../\")))\nsys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), \"../../\")))\n\n\nfrom helpers.datasets import partition_data, get_image_size, get_num_of_labels\nfrom helpers.utils import get_dataset, average_weights, DatasetSplit, KLDiv, setup_seed, test, progressive_test\nfrom helpers.exp_path import ExpTool\n\n\nfrom models.generator import Generator\nfrom models.nets import (CNNCifar, CNNMnist, CNNCifar100, \n                        make_CNNCifar_seqs, make_CNNCifar_Head_seqs)\nfrom models.pnn import PNN\nfrom models.pnn_cnn import PNN_CNN, pnn_resnet18, pnn_resnet50\n\nfrom models.fl_pnn import Federated_PNN\nfrom models.fl_pnn_cnn import Federated_PNN_CNN, fl_pnn_resnet18, fl_pnn_resnet50\nfrom models.mlp import MLP, make_MLP_seqs, make_MLP_Head_seqs, mlp2, mlp3\nfrom models.fl_exnn import (MLP_Block, CNN_Block,\n    merge_layer, Federated_EXNN, Federated_EXNNLayer_global, Federated_EXNNLayer_local,\n    fl_exnn_resnet18, fl_exnn_resnet50, \n)\nfrom models.seq_model import Sequential_SplitNN, ReconMIEstimator, LinearProbes\nfrom models.configs import Split_Configs, EXNN_Split_Configs\n\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nimport torch.nn.functional as F\n\nfrom models.resnet import (resnet18, resnet50, \n            resnet18_layers, resnet50_layers, \n            resnet18_head, resnet50_head, make_ResNetMIEstimator, get_res18_out_channels)\nfrom models.vit import deit_tiny_patch16_224\nimport wandb\n\nfrom models.auxiliary_nets import Decoder, AuxClassifier\n\nwarnings.filterwarnings('ignore')\nupsample = torch.nn.Upsample(mode='nearest', scale_factor=7)\n\nfrom locals.fedavg import LocalUpdate\nfrom locals.fl_progressive import FedPnnLocalUpdate\nfrom locals.progressive import PnnLocalUpdate\nfrom locals.fl_expandable import FedEXNNLocalUpdate\nfrom locals.ccvr import (compute_classes_mean_cov, generate_virtual_representation,\n    calibrate_classifier, get_means_covs_from_client)\n\nfrom alg_train import Ensemble, pretrain, progressive, fed_progressive, fed_expandable, init_fedexnn_merged\nfrom utils import seq_map_values, batch, accuracy, show_model_layers\n\nfrom helpers.meter import AverageMeter\n\nfrom tsne_draw import draw_tsne\n\n\n\n\ndef str2bool(v):\n    if isinstance(v, bool):\n        return v\n    # if v.lower() in ('yes', 'true', 't', 'y', '1'):\n    if isinstance(v, str) and v.lower() in ('true', 'True'):\n        return True\n    elif isinstance(v, str) and v.lower() in ('false', 'False'):\n        return False\n    else:\n        return v\n        # raise argparse.ArgumentTypeError('Boolean value expected.')\n\n\ndef logging_config(args, process_id):\n    # customize the log format\n    while logging.getLogger().handlers:\n        logging.getLogger().handlers.clear()\n    log = logging.getLogger()  # root logger\n    for hdlr in log.handlers[:]:  # remove all old handlers\n        log.removeHandler(hdlr)\n    logger = logging.getLogger()\n    logging.basicConfig(level=logging.INFO, \n                    format='%(asctime)s - %(filename)s[line:%(lineno)d] - %(levelname)s: %(message)s')\n    ch = logging.StreamHandler()\n    ch.setLevel(logging.WARNING)\n\n    formatter = logging.Formatter(\"%(asctime)s - %(filename)s[line:%(lineno)d] - %(levelname)s: %(message)s\")\n    ch.setFormatter(formatter)\n\n    logger.addHandler(ch)\n\n    logger.info(args)\n    return logger\n\n\n\ndef args_parser():\n    parser = argparse.ArgumentParser()\n    # federated arguments (Notation for the arguments followed from paper)\n    parser.add_argument('--epochs', type=int, default=10,\n                        help=\"number of rounds of training\")\n    parser.add_argument('--num_users', type=int, default=5,\n                        help=\"number of users: K\")\n    parser.add_argument('--frac', type=float, default=1,\n                        help='the fraction of clients: C')\n    parser.add_argument('--local_ep', type=int, default=100,\n                        help=\"the number of local epochs: E\")\n    parser.add_argument('--local_bs', type=int, default=128,\n                        help=\"local batch size: B\")\n    parser.add_argument('--lr', type=float, default=0.01,\n                        help='learning rate')\n    parser.add_argument('--momentum', type=float, default=0.9,\n                        help='SGD momentum (default: 0.5)')\n    # other arguments\n    parser.add_argument('--dataset', type=str, default='cifar10', help=\"name \\\n                        of dataset\")\n    parser.add_argument('--datadir', type=str, required=False, default=\"./data/\", help=\"Data directory\")\n    parser.add_argument('--iid', type=int, default=1,\n                        help='Default set to IID. Set to 0 for non-IID.')\n    parser.add_argument('--gpu', type=int, required=False, default=0)\n    parser.add_argument('--num_classes', type=int, default=10, help='.')\n    parser.add_argument('--sample_per_class', type=int, default=5000, help='.')\n    parser.add_argument('--num_layers', type=int, default=2, help='.')\n    parser.add_argument('--mlp_hidden_features', type=int, default=100, help='.')\n    parser.add_argument('--cnn_hidden_features', type=int, default=128, help='.')\n    parser.add_argument('--res_base_width', type=int, default=64, help='.')\n    parser.add_argument('--res_group_norm', type=int, default=0, help='.')\n\n\n    # Data Free\n    parser.add_argument('--adv', default=0, type=float, help='scaling factor for adv loss')\n\n    parser.add_argument('--bn', default=0, type=float, help='scaling factor for BN regularization')\n    parser.add_argument('--oh', default=0, type=float, help='scaling factor for one hot loss (cross entropy)')\n    parser.add_argument('--act', default=0, type=float, help='scaling factor for activation loss used in DAFL')\n    parser.add_argument('--save_dir', default='run/synthesis', type=str)\n    parser.add_argument('--partition', default='dirichlet', type=str)\n    parser.add_argument('--alpha', default=0.5, type=float,\n                        help=' If alpha is set to a smaller value, '\n                            'then the partition is more unbalanced')\n\n    # Basic\n    parser.add_argument('--lr_g', default=1e-3, type=float,\n                        help='initial learning rate for generation')\n    parser.add_argument('--T', default=1, type=float)\n    parser.add_argument('--g_steps', default=20, type=int, metavar='N',\n                        help='number of iterations for generation')\n    parser.add_argument('--batch_size', default=256, type=int, metavar='N',\n                        help='number of total iterations in each epoch')\n    parser.add_argument('--nz', default=256, type=int, metavar='N',\n                        help='number of total iterations in each epoch')\n    parser.add_argument('--synthesis_batch_size', default=256, type=int)\n\n    # Misc\n    parser.add_argument('--seed', default=None, type=int,\n                        help='seed for initializing training.')\n    parser.add_argument('--type', default=\"pretrain\", type=str,\n                        help='.')\n    parser.add_argument('--main_task', default=\"train\", type=str,\n                        help='.')   # train, MI, \n    parser.add_argument('--model', default=\"\", type=str,\n                        help='.')\n    parser.add_argument('--other', default=\"\", type=str,\n                        help='.')\n    parser.add_argument('--logging_level', default=\"INFO\", type=str,\n                        help='.')\n    parser.add_argument('--debug', default=\"False\", type=str,\n                        help='.')\n    parser.add_argument('--debug_show_exnn_id', default=\"False\", type=str,\n                        help='.')\n    # 'INFO' or 'DEBUG'\n\n    # federated progressive\n    parser.add_argument('--progressive_classifer', default=\"fixed\", type=str,\n                        help='.') # fixed, progressive\n\n    # federated expandable NN\n    parser.add_argument('--fedexnn_classifer', default=\"avg\", type=str,\n                        help='.') #   fixed   multihead\n    parser.add_argument('--fedexnn_adapter', default=\"avg\", type=str,\n                        help='.') \n    parser.add_argument('--fedexnn_split_num', default=2, type=int,\n                        help='.') \n    parser.add_argument('--fedexnn_hetero_layer_depth', default=\"False\", type=str,\n                        help='.') \n    parser.add_argument('--fedexnn_self_dropout', default=0.0, type=float,\n                        help='.') \n    parser.add_argument('--fedexnn_adapter_constrain_beta', default=0.0, type=float,\n                        help='.') \n\n    # split related \n    parser.add_argument('--split_train', default=\"False\", type=str,\n                        help='.') \n    parser.add_argument('--split_local_module_num', default=2, type=int,\n                        help='.') \n    parser.add_argument('--split_measure_local_module_num', default=2, type=int,\n                        help='.') \n    parser.add_argument('--infopro', default=2, type=int,\n                        help='.') \n    parser.add_argument('--MI_cos_lr', default=\"False\", type=str,\n                        help='.') \n\n    # contrastive train\n    parser.add_argument('--contrastive_train', default=\"False\", type=str,\n                        help='.')\n    parser.add_argument('--contrastive_n_views', default=2, type=int,\n                        help='.')\n    parser.add_argument('--contrastive_weight', default=1.0, type=float,\n                        help='.')\n    parser.add_argument('--contrastive_projection_dim', default=64, type=int,\n                        help='.')\n\n    # backdoor train\n    parser.add_argument('--backdoor_train', default=\"False\", type=str,\n                        help='.')\n    parser.add_argument('--backdoor_n_clients', default=1, type=int,\n                        help='.')\n    parser.add_argument('--backdoor_size', default=10, type=int,\n                        help='.')\n\n\n    parser.add_argument('--checkpoint', default='no', type=str, metavar='PATH',\n                        help='path to save checkpoint (default: checkpoint)')\n    parser.add_argument('--resume', default='', type=str,\n                        help='path to latest checkpoint (default: none)')\n\n\n    # spurious related \n    parser.add_argument('--spufeat', default=\"\", type=str,\n                        help='.') \n    parser.add_argument('--aux_net_config', default='1c2f', type=str,\n                        help='architecture of auxiliary classifier / contrastive head '\n                            '(default: 1c2f; 0c1f refers to greedy SL)'\n                            '[0c1f|0c2f|1c1f|1c2f|1c3f|2c2f]')\n    parser.add_argument('--local_loss_mode', default='contrast', type=str,\n                        help='ways to estimate the task-relevant info I(x, y)'\n                            '[contrast|cross_entropy]')\n    parser.add_argument('--aux_net_widen', default=1.0, type=float,\n                        help='widen factor of the two auxiliary nets (default: 1.0)')\n    parser.add_argument('--aux_net_feature_dim', default=0, type=int,\n                        help='number of hidden features in auxiliary classifier / contrastive head '\n                            '(default: 128)')\n    parser.add_argument('--ixx_1', default=0.0, type=float,)   # \\lambda_1 for 1st local module\n    parser.add_argument('--ixy_1', default=0.0, type=float,)   # \\lambda_2 for 1st local module\n\n    parser.add_argument('--ixx_2', default=0.0, type=float,)   # \\lambda_1 for (K-1)th local module\n    parser.add_argument('--ixy_2', default=0.0, type=float,)   # \\lambda_2 for (K-1)th local module\n\n    # EstMI\n    parser.add_argument('--EstMI_method', default=\"infopro\", type=str,\n                        help='number of local modules (1 refers to end-to-end training)')\n    parser.add_argument('--EstFeatNorm', default=\"no\", type=str, help='')\n    parser.add_argument('--SaveFeats', default=\"no\", type=str, help='')\n    parser.add_argument('--TSNE', default=\"no\", type=str, help='')\n    parser.add_argument('--TSNE_points', default=500, type=int, help='')\n\n\n    # wandb, exp record related\n    parser.add_argument(\"--wandb_offline\", type=str, default=\"True\")\n    parser.add_argument(\"--wandb_console\", type=str, default=\"False\")\n    parser.add_argument(\"--wandb_entity\", type=str, default=\"your-wandb-entity\")\n    parser.add_argument(\"--wandb_key\", type=str, default=None)\n\n    parser.add_argument(\"--exp_abs_path\", type=str, default=\".\")\n    parser.add_argument(\"--project_name\", type=str, default=\"your-wandb-project\")\n    parser.add_argument(\"--exp_name\", type=str, default=\"OneShot-FL\")\n    parser.add_argument(\"--override_cmd_args\", action=\"store_true\")\n    parser.add_argument(\"--tag\", type=str, default=\"debug\")\n    parser.add_argument(\"--exp_tool_init_sub_dir\", type=str, default=\"no\")\n\n    parser.add_argument(\"--enable_wandb\", type=str, default=\"False\")\n\n\n    args = parser.parse_args()\n    for key in args.__dict__.keys():\n        args.__dict__[key] = str2bool(args.__dict__[key])\n    return args\n\n\n\ndef kd_train(synthesizer, model, criterion, optimizer):\n    student, teacher = model\n    student.train()\n    teacher.eval()\n    description = \"loss={:.4f} acc={:.2f}%\"\n    total_loss = 0.0\n    correct = 0.0\n    with tqdm(synthesizer.get_data()) as epochs:\n        for idx, (images) in enumerate(epochs):\n            optimizer.zero_grad()\n            images = images\n            with torch.no_grad():\n                t_out = teacher(images)\n            s_out = student(images.detach())\n            loss_s = criterion(s_out, t_out.detach())\n\n            loss_s.backward()\n            optimizer.step()\n\n            total_loss += loss_s.detach().item()\n            avg_loss = total_loss / (idx + 1)\n            pred = s_out.argmax(dim=1)\n            target = t_out.argmax(dim=1)\n            correct += pred.eq(target.view_as(pred)).sum().item()\n            acc = correct / len(synthesizer.data_loader.dataset) * 100\n\n            epochs.set_description(description.format(avg_loss, acc))\n\n\ndef save_checkpoint(state, is_best, filename='checkpoint.pth'):\n    if is_best:\n        torch.save(state, filename)\n\n\ndef get_data_info(args):\n    if args.dataset == \"mnist\":\n        image_size = 28\n        linear_in_feautres = image_size * image_size * 1\n        channels = 1\n    elif args.dataset == \"fmnist\":\n        image_size = 28\n        linear_in_feautres = image_size * image_size * 1\n        channels = 1\n    elif args.dataset == \"SVHN\":\n        image_size = 32\n        linear_in_feautres = image_size * image_size * 3\n        channels = 3\n    elif args.dataset == \"cifar10\":\n        image_size = 32\n        linear_in_feautres = image_size * image_size * 3\n        channels = 3\n    elif args.dataset == \"cifar100\":\n        image_size = 32\n        linear_in_feautres = image_size * image_size * 3\n        channels = 3\n    elif args.dataset == \"Tiny-ImageNet-200\":\n        image_size = 64\n        linear_in_feautres = image_size * image_size * 3\n        channels = 3\n    else:\n        pass\n    return image_size, linear_in_feautres, channels\n\n\ndef get_model(args, num_of_classes=10):\n    linear_in_feautres = None\n    dataset = args.dataset\n    # split_config = Split_Configs[args.model][args.split_local_module_num]\n    # split_measure_config = Split_Configs[args.model][args.split_measure_local_module_num]\n  \n    # split_measure_config = EXNN_Split_Configs[args.model][args.split_measure_local_module_num]\n    #the only changes in this file were due to vgg-9 constraints so not changing it is also viable\n\n    layers = None\n    image_size, linear_in_feautres, channels = get_data_info(args)\n    if args.type == \"fed-expandable\":\n        small_layers = None\n        large_layers = None\n        if args.model == \"mlp3\":\n            hidden_features = args.mlp_hidden_features\n            layers = mlp3(linear_in_feautres, hidden_features, num_of_classes, init_classifier=False)\n            if args.fedexnn_hetero_layer_depth:\n                small_layers = mlp3(linear_in_feautres, hidden_features // 2, num_of_classes, init_classifier=False)\n                large_layers = mlp3(linear_in_feautres, int(hidden_features * 1.5), num_of_classes, init_classifier=False)\n        elif args.model == \"cnn\":\n            hidden_features = args.cnn_hidden_features\n            layers = make_CNNCifar_seqs(3, hidden_features, num_of_classes, init_classifier=False)\n        elif args.model == \"resnet18\":\n            split_local_layers = fl_exnn_resnet18(group_norm=args.res_group_norm,\n                                            res_base_width=args.res_base_width, in_channels=channels, \n                                            hetero_layer_depth=args.fedexnn_hetero_layer_depth)\n            layers, small_layers, large_layers = split_local_layers\n        elif args.model == \"resnet50\":\n            split_local_layers = fl_exnn_resnet50(group_norm=args.res_group_norm,\n                                            res_base_width=args.res_base_width, in_channels=channels, \n                                            hetero_layer_depth=args.fedexnn_hetero_layer_depth)\n            layers, small_layers, large_layers = split_local_layers\n        else:\n            raise NotImplementedError\n\n        # split_config = Split_Configs[args.model][args.fedexnn_split_num]\n\n        split_config = EXNN_Split_Configs[args.model][args.fedexnn_split_num]\n\n        begin_index = 0\n        split_modules = []\n        for layer_index in split_config:\n            split_module = Sequential_SplitNN(None, None, \n                                None, None,\n                                layers[begin_index: layer_index+1])\n            begin_index = layer_index + 1\n            split_modules.append(split_module)\n        split_module = Sequential_SplitNN(None, None, \n                            None, None,\n                            layers[begin_index:])\n        split_modules.append(split_module)\n        assert len(split_modules) == args.fedexnn_split_num\n\n        return layers, split_modules\n\n\n    if args.type == \"progressive\":\n        # if args.model == \"pnn\":\n        if args.model == \"mlp3\":\n            hidden_features = args.mlp_hidden_features\n            model = PNN(num_layers=args.num_layers,\n                            in_features=linear_in_feautres,\n                            hidden_features_per_column=hidden_features,\n                            num_of_classes=num_of_classes)\n        # elif args.model == \"pnn-cnn\":\n        elif args.model == \"cnn\":\n            hidden_features = args.cnn_hidden_features\n            model = PNN_CNN(num_layers=args.num_layers,\n                        in_features=channels,\n                        hidden_features_per_column=hidden_features,\n                        num_of_classes=num_of_classes,\n                        adapter=\"cnn\",\n                        )\n        elif args.model == \"resnet18\":\n            model = pnn_resnet18(num_classes=num_of_classes, group_norm=args.res_group_norm,\n                                res_base_width=args.res_base_width, in_channels=channels, adapter=\"cnn\")\n        elif args.model == \"resnet50\":\n            model = pnn_resnet50(num_classes=num_of_classes, group_norm=args.res_group_norm,\n                                res_base_width=args.res_base_width, in_channels=channels, adapter=\"cnn\")\n        return model\n\n\n    if args.type == \"fed-progressive\":\n        # if args.model == \"fl-pnn\":\n        if args.model == \"mlp3\":\n            hidden_features = args.mlp_hidden_features\n            model = Federated_PNN(num_layers=args.num_layers,\n                            in_features=3,\n                            hidden_features_per_column=hidden_features,\n                            num_of_classes=num_of_classes,\n                            classifier_name=args.progressive_classifer\n                            )\n        # elif args.model == \"fl-pnn-cnn\":\n        elif args.model == \"cnn\":\n            hidden_features = args.cnn_hidden_features\n            model = Federated_PNN_CNN(num_layers=args.num_layers,\n                        in_features=channels,\n                        hidden_features_per_column=hidden_features,\n                        num_of_classes=num_of_classes,\n                        adapter=\"cnn\",\n                        classifier_name=args.progressive_classifer\n                    )\n        elif args.model == \"resnet18\":\n            model = fl_pnn_resnet18(num_classes=num_of_classes, group_norm=args.res_group_norm,\n                                res_base_width=args.res_base_width, in_channels=channels,\n                                adapter=\"cnn\", classifier_name=args.progressive_classifer)\n        elif args.model == \"resnet50\":\n            model = fl_pnn_resnet50(num_classes=num_of_classes, group_norm=args.res_group_norm,\n                                res_base_width=args.res_base_width, in_channels=channels,\n                                adapter=\"cnn\", classifier_name=args.progressive_classifer)\n        return model\n\n    if args.model == \"mnist_cnn\":\n        model = CNNMnist()\n    elif args.model == \"fmnist_cnn\":\n        model = CNNMnist()\n    elif args.model == \"cnn\":\n        hidden_features = args.cnn_hidden_features\n        # model = CNNCifar(hidden_features, num_of_classes)\n        layers = make_CNNCifar_seqs(3, hidden_features, num_of_classes, init_classifier=False)\n        model = Sequential_SplitNN(args.split_train, split_config, \n                            split_measure_config, args.split_local_module_num,\n                            layers)\n    elif args.model == \"mlp2\":\n        hidden_features = args.mlp_hidden_features\n        layers = mlp2(linear_in_feautres, hidden_features, num_of_classes, init_classifier=True)\n        model = Sequential_SplitNN(args.split_train, split_config, \n                            split_measure_config, args.split_local_module_num,\n                            layers)\n    elif args.model == \"mlp3\":\n        hidden_features = args.mlp_hidden_features\n        layers = mlp3(linear_in_feautres, hidden_features, num_of_classes, init_classifier=True)\n        model = Sequential_SplitNN(args.split_train, split_config, \n                            split_measure_config, args.split_local_module_num,\n                            layers)\n\n    elif args.model == \"svhn_cnn\":\n        hidden_features = args.cnn_hidden_features\n        model = CNNCifar(hidden_features, num_of_classes)\n    elif args.model == \"cifar100_cnn\":\n        model = CNNCifar100()\n    elif args.model == \"resnet18\":\n        # model = resnet18(num_classes=num_of_classes, group_norm=args.res_group_norm, res_base_width=args.res_base_width, in_channels=channels)\n        layers = resnet18_layers(init_classifier=True,\n            num_classes=num_of_classes, group_norm=args.res_group_norm, res_base_width=args.res_base_width, in_channels=channels)\n        model = Sequential_SplitNN(args.split_train, split_config, \n                            split_measure_config, args.split_local_module_num,\n                            layers)\n        # resnet18_head, resnet50_head\n    elif args.model == \"resnet50\":\n        layers = resnet50_layers(init_classifier=True,\n            num_classes=num_of_classes, group_norm=args.res_group_norm, res_base_width=args.res_base_width, in_channels=channels)\n        model = Sequential_SplitNN(args.split_train, split_config, \n                            split_measure_config, args.split_local_module_num,\n                            layers)\n\n    elif args.model == \"vit\":\n        model = deit_tiny_patch16_224(num_classes=num_of_classes,\n                                             drop_rate=0.,\n                                             drop_path_rate=0.1)\n        model.head = torch.nn.Linear(model.head.in_features, num_of_classes)\n        model = torch.nn.DataParallel(model)\n\n    return layers, model\n\n\ndef adjust_learning_rate(optimizer, epoch, training_configurations, args):\n    \"\"\"Sets the learning rate\"\"\"\n    if not args.MI_cos_lr:\n        if epoch in training_configurations[args.model]['changing_lr']:\n            for param_group in optimizer.param_groups:\n                param_group['lr'] *= training_configurations[args.model]['lr_decay_rate']\n        print('lr:')\n        for param_group in optimizer.param_groups:\n            print(param_group['lr'])\n\n    else:\n        for param_group in optimizer.param_groups:\n            if epoch <= 10:\n                param_group['lr'] = 0.5 * training_configurations[args.model]['initial_learning_rate']\\\n                                * (1 + math.cos(math.pi * epoch / training_configurations[args.model]['epochs'])) * (epoch - 1) / 10 + 0.01 * (11 - epoch) / 10\n            else:\n                param_group['lr'] = 0.5 * training_configurations[args.model]['initial_learning_rate']\\\n                                    * (1 + math.cos(math.pi * epoch / training_configurations[args.model]['epochs']))\n        print('lr:')\n        for param_group in optimizer.param_groups:\n            print(param_group['lr'])\n\n\n\n\ndef measure_feautre(device, data_loader, model):\n    \"\"\"Eval for one epoch on the training set\"\"\"\n    model.eval()\n    layer_channel_norms = {}\n    layer_total_norm = {}\n\n    total_batches = 0\n    with torch.no_grad():\n        for i, (x, target) in enumerate(data_loader):\n            target = target.to(device)\n            x = x.to(device)\n            output, hidden_xs = model.forward_measure(x)\n            if args.type == \"fed-expandable\":\n                hidden_xs = to_exnn_hidden_xs(hidden_xs)\n            for layer_idx, features in hidden_xs.items():\n                # norm on height and weight, output shape is [batch_size, num_channels]\n                norms = torch.norm(features, p=2, dim=[2, 3])\n\n                # average for mini-batch\n                # shape is [num_channels]\n                batch_mean_norms = torch.mean(norms, dim=0)\n                if layer_idx not in layer_channel_norms:\n                    layer_channel_norms[layer_idx] = batch_mean_norms\n                else:\n                    layer_channel_norms[layer_idx] += batch_mean_norms\n            total_batches += 1\n\n    for layer_idx in layer_channel_norms.keys():\n        layer_channel_norms[layer_idx] = (layer_channel_norms[layer_idx] / total_batches)\n        layer_total_norm[layer_idx] = torch.norm(layer_channel_norms[layer_idx], p=2).item()\n    return layer_channel_norms, layer_total_norm\n\n\ndef get_all_feature(device, data_loader, model, num_points=1000):\n    model.eval()\n\n    layer_feats = {}\n    labels = []\n    loaded_num_points = 0\n\n    with torch.no_grad():\n        for i, (x, target) in enumerate(data_loader):\n            x = x.to(device)\n            loaded_num_points += x.shape[0]\n            output, hidden_xs = model.forward_measure(x)\n            if args.type == \"fed-expandable\":\n                hidden_xs = to_exnn_hidden_xs(hidden_xs)\n            labels.append(target)\n            for layer_idx, features in hidden_xs.items():\n                if layer_idx not in layer_feats:\n                    layer_feats[layer_idx] = []\n                layer_feats[layer_idx].append(features)\n            if loaded_num_points > num_points:\n                break\n        for layer_idx in layer_feats.keys():\n            layer_feats[layer_idx] = torch.cat(layer_feats[layer_idx], dim=0)[:num_points].to('cpu')\n        labels = torch.cat(labels, dim=0)[:num_points]\n\n    return layer_feats, labels\n\n\n\n\n\n\ndef estMI(device, train_loader, model, estimator, optimizer, epoch, num_layers):\n    \"\"\"Train for one epoch on the training set\"\"\"\n    layer_top1s = [AverageMeter() for _ in range(num_layers)]\n\n    record_file = ExpTool.get_file_name(\"EstiMI.txt\", exp_dir=True)\n    model.eval()\n\n    loss_ixx_modules_iters = []\n    loss_ixy_modules_iters = []\n\n    local_iters = len(train_loader)\n\n    for i, (x, target) in enumerate(train_loader):\n        target = target.to(device)\n        x = x.to(device)\n\n        optimizer.zero_grad()\n        output, hidden_xs = model.forward_measure(x)\n        if args.type == \"fed-expandable\":\n            hidden_xs = to_exnn_hidden_xs(hidden_xs)\n\n        # show_model_layers(model, logger=None)\n        # for k, decode in decoders.items():\n        #     logger.info(f\"====decoder {k}==============================\")\n        #     show_model_layers(decode, logger)\n        #     logger.info(f\"====aux_classifier {k}==============================\")\n        #     show_model_layers(aux_classifiers[k], logger)\n\n        # for layer_index, hidden_x in hidden_xs.items():\n        #     logging.info(f\"layer: {layer_index}, has tensor shape: {hidden_x.shape}\")\n\n        h_logits, loss_ixx_modules, loss_ixy_modules = estimator(x, hidden_xs, target)\n\n        loss_ixx_modules_iters.append(loss_ixx_modules)\n        loss_ixy_modules_iters.append(loss_ixy_modules)\n        optimizer.step()\n\n        for layer_i, logits in enumerate(h_logits):\n            prec1 = accuracy(logits.data, target, topk=(1,))[0]\n            layer_top1s[layer_i].update(prec1.item(), x.size(0))\n\n        if (i+1) % 10 == 0:\n            # print(discriminate_weights)\n            fd = open(record_file, 'a+')\n            string = f\"Training Epoch: [{epoch}][{i}/{local_iters}], loss_ixx: {[round(loss_ixx, 3) for loss_ixx in loss_ixx_modules]} \" + \\\n                f\"loss_ixy: {[round(loss_ixy, 3) for loss_ixy in loss_ixy_modules]} \" + \\\n                f\"top1s: {[round(top1s.val, 3) for top1s in layer_top1s]} \"\n\n            logging.info(string)\n            # print(weights)\n            fd.write(string + '\\n')\n            fd.close()\n\n    loss_ixx_modules_iters = np.array(loss_ixx_modules_iters)\n    loss_ixy_modules_iters = np.array(loss_ixy_modules_iters)\n    loss_ixx_modules_iters = np.mean(loss_ixx_modules_iters, axis=0)\n    loss_ixy_modules_iters = np.mean(loss_ixy_modules_iters, axis=0)\n    fd = open(record_file, 'a+')\n    string = f\"Training Epoch: [{epoch}], loss_ixx avg: {[round(loss_ixx, 3) for loss_ixx in loss_ixx_modules_iters]} \" + \\\n            f\"loss_ixy avg: {[round(loss_ixy, 3) for loss_ixy in loss_ixy_modules_iters]} \" + \\\n            f\"top1s avg: {[round(top1s.avg, 3) for top1s in layer_top1s]} \"\n    logging.info(string)\n    fd.write(string + '\\n')\n    fd.close()\n    loss_ixxs = [round(loss_ixx, 3) for loss_ixx in loss_ixx_modules_iters]\n    top1s_avg = [round(top1s.avg, 3) for top1s in layer_top1s]\n\n    return loss_ixxs, top1s_avg\n\n\n\ndef train_linear_probe(device, train_loader, model, linear_probes, optimizer, epoch, num_layers):\n    \"\"\"Train for one epoch on the training set\"\"\"\n    layer_top1s = [AverageMeter() for _ in range(num_layers)]\n\n    record_file = ExpTool.get_file_name(\"EstiMI.txt\", exp_dir=True)\n    model.eval()\n\n    loss_ixys_iters = []\n    local_iters = len(train_loader)\n    for i, (x, target) in enumerate(train_loader):\n        target = target.to(device)\n        x = x.to(device)\n\n        optimizer.zero_grad()\n        output, hidden_xs = model.forward_measure(x)\n        if args.type == \"fed-expandable\":\n            hidden_xs = to_exnn_hidden_xs(hidden_xs)\n        h_logits, loss_ixys = linear_probes(x, hidden_xs, target)\n        loss_ixys_iters.append(loss_ixys)\n        optimizer.step()\n\n        for layer_i, logits in enumerate(h_logits):\n            prec1 = accuracy(logits.data, target, topk=(1,))[0]\n            layer_top1s[layer_i].update(prec1.item(), x.size(0))\n\n        if (i+1) % 10 == 0:\n            # print(discriminate_weights)\n            fd = open(record_file, 'a+')\n            string = f\"Training Epoch: [{epoch}][{i}/{local_iters}], \" + \\\n                f\"loss_ixy: {[round(loss_ixy, 3) for loss_ixy in loss_ixys]} \" + \\\n                f\"top1s: {[round(top1s.val, 3) for top1s in layer_top1s]} \"\n\n            logging.info(string)\n            # print(weights)\n            fd.write(string + '\\n')\n            fd.close()\n    loss_ixys_iters = np.array(loss_ixys_iters)\n    loss_ixys_iters = np.mean(loss_ixys_iters, axis=0)\n    fd = open(record_file, 'a+')\n    string = f\"Training Epoch: [{epoch}],\" + \\\n            f\"loss_ixy avg: {[round(loss_ixy, 3) for loss_ixy in loss_ixys_iters]} \" + \\\n            f\"top1s avg: {[round(top1s.avg, 3) for top1s in layer_top1s]} \"\n    logging.info(string)\n    fd.write(string + '\\n')\n    fd.close()\n    top1s_avg = [round(top1s.avg, 3) for top1s in layer_top1s]\n\n    return top1s_avg\n\n\n\ndef get_res_MIEstimator(split_measure_config, num_of_classes, group_norm, res_base_width, channels):\n    layers = resnet18_layers(init_classifier=True,\n        num_classes=num_of_classes, group_norm=group_norm, res_base_width=res_base_width, in_channels=channels)\n\n    decoders, aux_classifiers = make_ResNetMIEstimator(\n        layers, hidden_x_channels, image_size, aux_net_widen=1)\n\n    mi_estimator = ReconMIEstimator(split_measure_config)\n\n    for layer_index, decoder in decoders.items(): \n        mi_estimator.add_decoder(decoder, layer_index)\n    for layer_index, aux_classifier in aux_classifiers.items(): \n        mi_estimator.add_aux_classifier(aux_classifier, layer_index)\n    return mi_estimator\n\n\n\nif __name__ == '__main__':\n\n    args = args_parser()\n\n    if args.main_task == \"train\":\n        ExpTool.init(args)\n    elif args.main_task in [\"MI\", \"LinearProbe\"]:\n        if not args.exp_tool_init_sub_dir == \"no\":\n            ExpTool.init_with_sub_dir(args, args.exp_tool_init_sub_dir)\n        else:\n            ExpTool.init(args)\n    else:\n        raise NotImplementedError\n\n    logger = logging_config(args, 0)\n    # wandb.init(config=args,\n    #            project=\"ont-shot FL\")\n\n    device = torch.device(f\"cuda:{args.gpu}\")\n    setup_seed(args.seed)\n    # pdb.set_trace()\n    image_size = get_image_size(args.dataset)\n    num_of_classes = get_num_of_labels(args.dataset)\n    train_dataset, test_dataset, train_user_groups, train_data_cls_counts, test_user_groups, test_data_cls_counts = partition_data(\n        image_size, args.dataset, args.datadir, args.partition, alpha=args.alpha, num_users=args.num_users,\n        contrastive_train=args.contrastive_train, contrastive_n_views=args.contrastive_n_views)\n\n    logger.info(f\"train_data_cls_counts: {train_data_cls_counts}\")\n    logger.info(f\"test_data_cls_counts: {test_data_cls_counts}\")\n\n    global_test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=256,\n                                              shuffle=False, num_workers=4)\n    # BUILD MODEL\n\n    mi_estimator_configurations = {\n        'resnet18': {\n            'epochs': 160,\n            'batch_size': 128,\n            'initial_learning_rate': 0.01,\n            # 'batch_size': 1024 if args.dataset in ['cifar10', 'svhn'] else 128,\n            # 'initial_learning_rate': 0.8 if args.dataset in ['cifar10', 'svhn'] else 0.1,\n            'changing_lr': [80, 120],\n            'lr_decay_rate': 0.1,\n            'momentum': 0.9,\n            'nesterov': True,\n            'weight_decay': 1e-4,\n        },\n        'resnet50': {\n            'epochs': 160,\n            'batch_size': 1024 if args.dataset in ['cifar10', 'svhn'] else 128,\n            'initial_learning_rate': 0.8 if args.dataset in ['cifar10', 'svhn'] else 0.1,\n            'changing_lr': [80, 120],\n            'lr_decay_rate': 0.1,\n            'momentum': 0.9,\n            'nesterov': True,\n            'weight_decay': 1e-4,\n        },\n    }\n\n    linear_probe_configurations = {\n        'resnet18': {\n            'epochs': 10,\n            'batch_size': 128,\n            'initial_learning_rate': 0.01,\n            'momentum': 0.9,\n            'nesterov': True,\n            'weight_decay': 1e-4,\n        },\n    }\n\n    layers, global_model = get_model(args, num_of_classes)\n    # split_measure_config = EXNN_Split_Configs[args.model][args.split_measure_local_module_num]\n    # split_measure_config = Split_Configs[args.model][args.split_measure_local_module_num]\n    image_size, linear_in_feautres, channels = get_data_info(args)\n\n    if args.model == \"resnet18\":\n        out_channels = get_res18_out_channels(args.res_base_width)\n    elif args.model == \"mlp2\":\n        out_channels = [args.mlp_hidden_features for _ in range(2)]\n    elif args.model == \"mlp3\":\n        out_channels = [args.mlp_hidden_features for _ in range(3)]\n    elif args.model == \"cnn\":\n        out_channels = [args.cnn_hidden_features for _ in range(3)]\n    else:\n        raise NotImplementedError\n\n\n    if args.main_task == \"train\":\n        if args.type == \"pretrain\":\n            global_model, global_weights, local_weights, model_list = pretrain(\n                args, device, logger, train_dataset, test_dataset, \n                train_user_groups, train_data_cls_counts, \n                test_user_groups, test_data_cls_counts,\n                global_test_loader, global_model, out_channels)\n        elif args.type == \"progressive\":\n            progressive(args, device, logger, train_dataset, test_dataset, \n            train_user_groups, train_data_cls_counts, \n            test_user_groups, test_data_cls_counts,\n            global_test_loader, global_model, out_channels)\n        elif args.type == \"fed-progressive\":\n            fed_progressive(args, device, logger, train_dataset, test_dataset, \n            train_user_groups, train_data_cls_counts, \n            test_user_groups, test_data_cls_counts,\n            global_test_loader, global_model, out_channels)\n        elif args.type == \"fed-expandable\":\n            fed_expandable(args, device, logger, train_dataset, test_dataset, \n            train_user_groups, train_data_cls_counts, \n            test_user_groups, test_data_cls_counts,\n            global_test_loader, global_model, out_channels)\n        else:\n            raise RuntimeError\n\n    elif args.main_task == \"MI\":\n        if args.type == \"pretrain\":\n            assert args.resume\n            local_weights = ExpTool.load_pickle(args.resume, exp_dir=False)\n            model_list = []\n            for i in range(len(local_weights)):\n                net = copy.deepcopy(global_model)\n                net.load_state_dict(local_weights[i])\n                model_list.append(net)\n            ensemble_model = Ensemble(model_list)\n            # global_model_test_acc, test_loss = test(global_model, global_test_loader, device)\n            # logger.info(f\"global_model acc: {global_model_test_acc}\")\n\n            local_model = model_list[0]\n            # local_model_test_acc, test_loss = test(local_model, global_test_loader, device)\n            # logger.info(f\"local_model acc: {local_model_test_acc}\")\n\n            # ensemble_acc, ensemble_loss = test(ensemble_model, global_test_loader, device)\n            # logger.info(f\"ensemble acc: {ensemble_acc}\")\n            measure_model = local_model\n            if not args.EstFeatNorm == \"no\":\n                idx = 0\n                local_train_loader = DataLoader(DatasetSplit(train_dataset, train_user_groups[idx]),\n                                            batch_size=args.local_bs, shuffle=True, num_workers=4, drop_last=False)\n                local_test_loader = DataLoader(DatasetSplit(test_dataset, test_user_groups[idx]),\n                                            batch_size=args.local_bs, shuffle=False, num_workers=4, drop_last=False)\n                EstFeatNorm_results = {}\n                record_file = ExpTool.get_file_name(\"EstFeatNorm.txt\", exp_dir=True)\n                fd = open(record_file, 'a+')\n                for client_idx, model in enumerate(model_list):\n                    EstFeatNorm_results[client_idx] = {}\n                    model.to(device)\n                    layer_channel_norms, layer_total_norm = measure_feautre(device, local_train_loader, model)\n                    model.to(\"cpu\")\n                    EstFeatNorm_results[client_idx][\"layer_channel_norms\"] = layer_channel_norms\n                    EstFeatNorm_results[client_idx][\"layer_total_norm\"] = layer_total_norm\n                    for layer_idx, channel_norms in layer_channel_norms.items():\n                        ExpTool.logging_write(f\"client_idx:{client_idx}, layer_idx:{layer_idx}: layer_total_norm = {layer_total_norm[layer_idx]}\", fd)\n                        # ExpTool.logging_write(f\"channel_norms:{channel_norms} =============\", fd)\n                fd.close()\n                ExpTool.save_pickle(EstFeatNorm_results, \"EstFeatNorm_results\", exp_dir=True)\n                ExpTool.finish(args)\n                exit()\n\n            if not args.SaveFeats == \"no\":\n                local_FeatLabels_results = {}\n                for client_idx, model in enumerate(model_list):\n                    if client_idx > 1:\n                        break\n                    logging.info(f\"get client {client_idx} features\")\n                    model.to(device)\n                    layer_feats, labels = get_all_feature(device, global_test_loader, model, num_points=1000)\n                    model.to(\"cpu\")\n                    local_FeatLabels_results[client_idx] = {\n                        \"layer_feats\": layer_feats,\n                        \"labels\": labels}\n                ExpTool.save_pickle(local_FeatLabels_results, \"local_FeatLabels_results\", exp_dir=True)\n                # global_FeatLabels_results = {}\n                # for client_idx, model in enumerate(model_list):\n                #     logging.info(f\"get client {client_idx} features\")\n                #     model.to(device)\n                #     layer_feats, labels = get_all_feature(device, global_test_loader, model, num_points=1000)\n                #     model.to(\"cpu\")\n                #     global_FeatLabels_results[client_idx] = {\n                #         \"layer_feats\": layer_feats,\n                #         \"labels\": labels}\n                # ExpTool.save_pickle(global_FeatLabels_results, \"global_FeatLabels_results\", exp_dir=True)\n                # if not args.TSNE == \"no\":\n                ExpTool.load_pickle(\"local_FeatLabels_results\", exp_dir=True)\n                avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n                # avg_pool.to(device)\n                for client_idx in local_FeatLabels_results.keys():\n                    layer_feats = local_FeatLabels_results[client_idx][\"layer_feats\"]\n                    labels = local_FeatLabels_results[client_idx][\"labels\"]\n                    for layer_index, features in layer_feats.items():\n                        logging.info(f\"T-SNE on client {client_idx}, layer {layer_index} ...... \")\n                        tSNE_save_path = ExpTool.get_file_name(f\"local_c{client_idx}_l{layer_index}_TSNE.pdf\", exp_dir=True)\n                        if len(features.shape) > 2:\n                            features = avg_pool(features[:args.TSNE_points])\n                        features = features.view(features.shape[0], -1)\n                        draw_tsne(device, num_of_classes, features, labels[:args.TSNE_points],\n                            tSNE_save_path=tSNE_save_path)\n                # ExpTool.load_pickle(\"global_FeatLabels_results\", exp_dir=True)\n                # for client_idx in global_FeatLabels_results.keys():\n                #     layer_feats = global_FeatLabels_results[client_idx][\"layer_feats\"]\n                #     labels = global_FeatLabels_results[client_idx][\"labels\"]\n                #     for layer_index, features in layer_feats.items():\n                #         tSNE_save_path = ExpTool.get_file_name(f\"global_c{client_idx}_l{layer_index}_TSNE.pdf\", exp_dir=True)\n                #         draw_tsne(device, num_of_classes, layer_feats, labels,\n                #             tSNE_save_path=tSNE_save_path)\n                ExpTool.finish(args)\n                exit()\n\n\n        elif args.type == \"fed-expandable\":\n            assert args.resume\n            global_model = init_fedexnn_merged(args, global_model, out_channels)\n            weights = ExpTool.load_pickle(args.resume, exp_dir=False)\n            # show_model_layers(global_model, logger=None)\n            # logger.info(f\"================================\")\n            # for k, v in weights.items():\n            #     logger.info(f\"layer: {k}, Shape:{v.shape} No. Params: {v.numel()}\")\n            global_model.load_state_dict(weights)\n            # global_model.load(weights)\n            measure_model = global_model\n        else:\n            raise RuntimeError\n        in_channels = []\n        measure_model.eval()\n        measure_model.to(device)\n\n        for i, (x, target) in enumerate(global_test_loader):\n            target = target.to(device)\n            x = x.to(device)\n            output, hidden_xs = measure_model.forward_measure(x)\n            break\n\n        def to_exnn_hidden_xs(hidden_xs):\n            if args.type == \"fed-expandable\":\n                # map to normal layer index\n                split_config = EXNN_Split_Configs[args.model][args.fedexnn_split_num]\n                new_hidden_xs = {}\n                for module_idx, layer_idx in enumerate(split_config):\n                    new_hidden_xs[layer_idx] = hidden_xs[module_idx]\n            return new_hidden_xs\n\n        if args.type == \"fed-expandable\":\n            hidden_xs = to_exnn_hidden_xs(hidden_xs)\n\n        hidden_x_channels = dict([(k, h.shape[1]) for k, h in hidden_xs.items()])\n        logging.info(f\"========== hidden_x_channels: {hidden_x_channels}\")\n\n        if args.model in [\"resnet18\"]:\n            mi_estimator = get_res_MIEstimator(split_measure_config, num_of_classes, args.res_group_norm, args.res_base_width, channels)\n            global_train_loader = torch.utils.data.DataLoader(\n                train_dataset, batch_size=mi_estimator_configurations[args.model]['batch_size'],\n                shuffle=False, num_workers=4)\n            num_layers = args.split_measure_local_module_num\n\n            optimizer = torch.optim.SGD(\n                mi_estimator.parameters(),\n                lr=mi_estimator_configurations[args.model]['initial_learning_rate'],\n                momentum=mi_estimator_configurations[args.model]['momentum'],\n                nesterov=mi_estimator_configurations[args.model]['nesterov'],\n                weight_decay=mi_estimator_configurations[args.model]['weight_decay'])\n\n            # show_model_layers(global_model, logger)\n            # for k, decode in decoders.items():\n            #     logger.info(f\"====decoder {k}==============================\")\n            #     show_model_layers(decode, logger)\n            #     logger.info(f\"====aux_classifier {k}==============================\")\n            #     show_model_layers(aux_classifiers[k], logger)\n\n\n            mi_estimator.to(device)\n            MI_results = {}\n\n            for epoch in range(0, mi_estimator_configurations[args.model]['epochs']):\n                # adjust_learning_rate(optimizer, epoch + 1)\n                if args.debug and epoch == 1:\n                    break\n                adjust_learning_rate(optimizer, epoch, mi_estimator_configurations, args)\n                train_loss_ixxs, train_top1s_avg = estMI(device, global_train_loader, measure_model, mi_estimator, optimizer, epoch, num_layers)\n                if epoch % 10 == 0 or epoch == mi_estimator_configurations[args.model]['epochs'] - 1:\n                    MI_results[epoch] = {}\n                    loss_ixx_modules_iters = []\n                    loss_ixy_modules_iters = []\n                    layer_test_top1s = [AverageMeter() for _ in range(len(hidden_xs))]\n                    for i, (x, target) in enumerate(global_test_loader):\n                        target = target.to(device)\n                        x = x.to(device)\n                        output, hidden_xs = measure_model.forward_measure(x)\n                        if args.type == \"fed-expandable\":\n                            hidden_xs = to_exnn_hidden_xs(hidden_xs)\n                        h_logits, loss_ixx_modules, loss_ixy_modules = mi_estimator(x, hidden_xs, target)\n                        loss_ixx_modules_iters.append(loss_ixx_modules)\n                        loss_ixy_modules_iters.append(loss_ixy_modules)\n                        for layer_i, logits in enumerate(h_logits):\n                            prec1 = accuracy(logits.data, target, topk=(1,))[0]\n                            layer_test_top1s[layer_i].update(prec1.item(), x.size(0))\n\n                    record_file = ExpTool.get_file_name(\"EstiMI.txt\", exp_dir=True)\n                    loss_ixx_modules_iters = np.array(loss_ixx_modules_iters)\n                    loss_ixy_modules_iters = np.array(loss_ixy_modules_iters)\n                    loss_ixx_modules_iters = np.mean(loss_ixx_modules_iters, axis=0)\n                    loss_ixy_modules_iters = np.mean(loss_ixy_modules_iters, axis=0)\n                    fd = open(record_file, 'a+')\n\n                    string = f\"Testing Epoch: [{epoch}], loss_ixx avg: {[round(loss_ixx, 3) for loss_ixx in loss_ixx_modules_iters]} \" + \\\n                            f\"loss_ixy avg: {[round(loss_ixy, 3) for loss_ixy in loss_ixy_modules_iters]} \" + \\\n                            f\"top1s avg: {[round(top1s.avg, 3) for top1s in layer_test_top1s]} \"\n                    test_loss_ixxs = [round(loss_ixx, 3) for loss_ixx in loss_ixx_modules_iters]\n                    test_top1s_avg = [round(top1s.avg, 3) for top1s in layer_test_top1s]\n                    print(string)\n                    fd.write(string + '\\n')\n                    fd.close()\n                    MI_results[epoch][\"train_loss_ixxs\"] = train_loss_ixxs\n                    MI_results[epoch][\"train_top1s_avg\"] = train_top1s_avg\n                    MI_results[epoch][\"test_loss_ixxs\"] = test_loss_ixxs\n                    MI_results[epoch][\"test_top1s_avg\"] = test_top1s_avg\n            ExpTool.save_pickle(MI_results, \"MI_results\", exp_dir=True)\n        else:\n            raise NotImplementedError\n\n        ExpTool.finish(args)\n    elif args.main_task == \"LinearProbe\":\n        if args.type == \"pretrain\":\n            assert args.resume\n            local_weights = ExpTool.load_pickle(args.resume, exp_dir=False)\n            model_list = []\n            for i in range(len(local_weights)):\n                net = copy.deepcopy(global_model)\n                net.load_state_dict(local_weights[i])\n                model_list.append(net)\n            ensemble_model = Ensemble(model_list)\n            local_model = model_list[0]\n            measure_model = local_model\n        elif args.type == \"fed-expandable\":\n            assert args.resume\n            global_model = init_fedexnn_merged(args, global_model, out_channels)\n            weights = ExpTool.load_pickle(args.resume, exp_dir=False)\n            global_model.load_state_dict(weights)\n            measure_model = global_model\n        else:\n            raise RuntimeError\n        in_channels = []\n        measure_model.eval()\n        measure_model.to(device)\n\n        for i, (x, target) in enumerate(global_test_loader):\n            target = target.to(device)\n            x = x.to(device)\n            output, hidden_xs = measure_model.forward_measure(x)\n            break\n\n        def to_exnn_hidden_xs(hidden_xs):\n            if args.type == \"fed-expandable\":\n                # map to normal layer index\n                split_config = EXNN_Split_Configs[args.model][args.fedexnn_split_num]\n                new_hidden_xs = {}\n                for module_idx, layer_idx in enumerate(split_config):\n                    new_hidden_xs[layer_idx] = hidden_xs[module_idx]\n            return new_hidden_xs\n\n        if args.type == \"fed-expandable\":\n            hidden_xs = to_exnn_hidden_xs(hidden_xs)\n\n        hidden_x_channels = dict([(k, h.shape[1]) for k, h in hidden_xs.items()])\n        logging.info(f\"========== hidden_x_channels: {hidden_x_channels}\")\n        if args.model in [\"resnet18\"]:\n            linear_probes = LinearProbes()\n            for layer_index, h in hidden_xs.items():\n                linear_probes.add(layer_index, h[0].numel(), num_of_classes)\n            global_train_loader = torch.utils.data.DataLoader(\n                train_dataset, batch_size=linear_probe_configurations[args.model]['batch_size'],\n                shuffle=False, num_workers=4)\n            num_layers = args.split_measure_local_module_num\n\n            optimizer = torch.optim.SGD(\n                linear_probes.parameters(),\n                lr=linear_probe_configurations[args.model]['initial_learning_rate'],\n                momentum=linear_probe_configurations[args.model]['momentum'],\n                nesterov=linear_probe_configurations[args.model]['nesterov'],\n                weight_decay=linear_probe_configurations[args.model]['weight_decay'])\n            linear_probes.to(device)\n            linear_probe_results = {}\n            for epoch in range(0, linear_probe_configurations[args.model]['epochs']):\n                # adjust_learning_rate(optimizer, epoch + 1)\n                if args.debug and epoch == 1:\n                    break\n                top1s_avg = train_linear_probe(device, global_train_loader, measure_model, linear_probes, optimizer, epoch, num_layers)\n                if epoch % 10 == 0 or epoch == linear_probe_configurations[args.model]['epochs'] - 1:\n                    linear_probe_results[epoch] = {}\n                    loss_ixy_modules_iters = []\n                    layer_test_top1s = [AverageMeter() for _ in range(len(hidden_xs))]\n                    for i, (x, target) in enumerate(global_test_loader):\n                        target = target.to(device)\n                        x = x.to(device)\n                        output, hidden_xs = measure_model.forward_measure(x)\n                        if args.type == \"fed-expandable\":\n                            hidden_xs = to_exnn_hidden_xs(hidden_xs)\n                        h_logits, loss_ixy_modules = linear_probes(x, hidden_xs, target)\n                        loss_ixy_modules_iters.append(loss_ixy_modules)\n                        for layer_i, logits in enumerate(h_logits):\n                            prec1 = accuracy(logits.data, target, topk=(1,))[0]\n                            layer_test_top1s[layer_i].update(prec1.item(), x.size(0))\n\n                    record_file = ExpTool.get_file_name(\"LinearProbeResults.txt\", exp_dir=True)\n                    loss_ixy_modules_iters = np.array(loss_ixy_modules_iters)\n                    loss_ixy_modules_iters = np.mean(loss_ixy_modules_iters, axis=0)\n                    fd = open(record_file, 'a+')\n\n                    string = f\"Testing Epoch: [{epoch}], \" + \\\n                            f\"loss_ixy avg: {[round(loss_ixy, 3) for loss_ixy in loss_ixy_modules_iters]} \" + \\\n                            f\"top1s avg: {[round(top1s.avg, 3) for top1s in layer_test_top1s]} \"\n                    test_top1s_avg = [round(top1s.avg, 3) for top1s in layer_test_top1s]\n                    print(string)\n                    fd.write(string + '\\n')\n                    fd.close()\n                    linear_probe_results[epoch][\"test_top1s_avg\"] = test_top1s_avg\n\n    else:\n        raise NotImplementedError\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-12-27T19:17:48.385047Z","iopub.execute_input":"2025-12-27T19:17:48.385671Z","iopub.status.idle":"2025-12-27T19:17:48.410631Z","shell.execute_reply.started":"2025-12-27T19:17:48.385644Z","shell.execute_reply":"2025-12-27T19:17:48.409907Z"}},"outputs":[{"name":"stdout","text":"Overwriting main.py\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"%%writefile locals/fl_expandable.py\n\nfrom tqdm import tqdm\nimport numpy as np\nfrom itertools import chain\nimport logging\n\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nimport torch.nn.functional as F\n\nfrom helpers.datasets import partition_data\nfrom helpers.utils import get_dataset, average_weights, DatasetSplit, BackdoorDS, KLDiv, setup_seed, test, progressive_test\nfrom helpers.exp_path import ExpTool\nfrom locals.cl_loss.info_nce import INFONCE\nfrom models.losses import conv_balance_regularization\n\nfrom .ccvr import compute_classes_mean_cov, generate_virtual_representation, calibrate_classifier, get_means_covs_from_client\nfrom locals.attack import *\nfrom locals.cutpaste import *\nimport copy\n\ndef cut(x):\n    x_gen = copy.deepcopy(x.cpu().numpy())\n    half = int(x_gen.shape[2] / 2)\n    rnd = random.randint(0,5)\n    pl = random.randint(0,half-1)\n    pl2 = random.randint(0,half-1)\n    while (abs(pl-pl2)<half/2):\n        pl2 = random.randint(0,half-1)\n    if rnd <= 1:\n        x_gen[:,:,pl:pl+half] = x_gen[:,:,pl2:pl2+half]\n    elif rnd == 2:\n        x_gen[:,:,half:] = x_gen[:,:,:half]\n        x_gen[:,:,:half] = copy.deepcopy(x.cpu().numpy())[:,:,half:]\n    elif rnd <= 4:\n        x_gen[:,pl:pl+half,:] = x_gen[:,pl2:pl2+half,:]\n    else:\n        x_gen[:,half:,:] = x_gen[:,:half,:]\n        x_gen[:,:half,:] = copy.deepcopy(x.cpu().numpy())[:,half:,:]\n    x_gen = torch.Tensor(x_gen)\n\n    return x_gen\n\ndef rot(x):\n    #rnd = random.randint(0,20)\n    #if rnd < 21:\n    x_gen = copy.deepcopy(x.cpu().numpy())\n    half = int(x_gen.shape[2] / 2)\n    pl = random.randint(0,half-1)\n    rnd = random.randint(1,3)\n\n    x_gen[:,pl:pl+half,half:] = np.rot90(x_gen[:,pl:pl+half,half:],k=rnd,axes=(1,2))\n    x_gen[:,pl:pl+half,:half] = np.rot90(x_gen[:,pl:pl+half,:half],k=rnd,axes=(1,2))\n    x_gen = torch.Tensor(x_gen)\n    #else:\n    #    x_gen = op(copy.deepcopy(x))\n    #    if rnd < 20:\n    #        x_gen = torch.max(x_gen, x)\n    #    else:\n    #        x_gen = torch.min(x_gen, x)\n\n    return x_gen\n\ndef paint(x):\n    x_gen = copy.deepcopy(x.cpu().numpy())\n    size = int(x_gen.shape[2])\n    sq = 4\n    pl = random.randint(sq,size-sq*2)\n    pl2 = random.randint(sq,size-sq-1)\n    rnd = random.randint(0,1)\n    if rnd == 0:\n        for i in range(sq,size-sq):\n            x_gen[:,i,pl:pl+sq] = x_gen[:,pl2,pl:pl+sq]\n    elif rnd == 1:\n        for i in range(sq,size-sq):\n            x_gen[:,pl:pl+sq,i] = x_gen[:,pl:pl+sq,pl2]\n    x_gen = torch.Tensor(x_gen)\n\n    return x_gen\n\ndef blur(x):\n    rnd = random.randint(0,1)\n    sz = random.randint(1,4)*2+1\n    sz2 = random.randint(0,2)*2+1\n    if rnd == 0:\n        func = transforms.GaussianBlur(kernel_size=(sz, sz2), sigma=(10, 100))\n    else:\n        func = transforms.GaussianBlur(kernel_size=(sz2, sz), sigma=(10, 100))\n    \n    return func(x)\n\n\n\nclass FedEXNNLocalUpdate(object):\n    def __init__(self, args, train_dataset, test_dataset, global_test_loader, train_idxs, test_idxs,\n                 backdoor_train=False):\n        self.args = args\n        self.backdoor_train = backdoor_train\n        if backdoor_train:\n            self.train_loader = DataLoader(BackdoorDS(DatasetSplit(train_dataset, train_idxs), args.backdoor_size),\n                                        batch_size=self.args.local_bs, shuffle=True, num_workers=4, drop_last=False)\n        else:\n            self.train_loader = DataLoader(DatasetSplit(train_dataset, train_idxs),\n                                        batch_size=self.args.local_bs, shuffle=True, num_workers=4, drop_last=False)\n        self.test_loader = DataLoader(DatasetSplit(test_dataset, test_idxs),\n                                       batch_size=self.args.local_bs, shuffle=False, num_workers=4, drop_last=False)\n        \n        self.global_test_loader = global_test_loader\n        self.info_nce = INFONCE(args.contrastive_n_views)\n\n    def add_CL_head(self, CL_head):\n        self.CL_head = CL_head\n\n    def load_global_model(self):\n        pass\n\n    def update_weights(self, client_id, epochs, model, device, if_test):\n        num_class = 11\n        sz=32        \n        model.train()\n        model.to(device)\n\n        optimizer = torch.optim.SGD(model.parameters(), lr=self.args.lr,\n                                    momentum=0.9)\n        criterion = torch.nn.CrossEntropyLoss()\n        attack = FastGradientSignUntargeted(model, \n                                            epsilon=0.5, \n                                            alpha=0.002, \n                                            min_val=0, \n                                            max_val=1, \n                                            max_iters=5,\n                                            device=device)\n        toImg = transforms.ToPILImage()\n        toTensor = transforms.ToTensor()\n    \n        op = transforms.RandomChoice( [\n            transforms.RandomRotation(degrees=(15,75)),\n            transforms.RandomRotation(degrees=(-75,-15)),\n            transforms.RandomRotation(degrees=(85,90)),\n            transforms.RandomRotation(degrees=(-90,-85)),\n            transforms.RandomRotation(degrees=(175,180)),\n        ])\n    \n        aug = transforms.Compose([\n            toImg,\n            op,\n            toTensor\n        ])\n\n        aug_crop =  transforms.RandomChoice( [\n            transforms.RandomResizedCrop(sz, scale=(0.1, 0.33)), \n            transforms.Lambda(lambda img: blur(img)), \n            transforms.RandomErasing(p=1, scale=(0.33, 0.5)), \n            transforms.Lambda(lambda img: cut(img)), \n            transforms.Lambda(lambda img: rot(img)),\n            transforms.Lambda(lambda img: cut(img)),\n            transforms.Lambda(lambda img: rot(img)),\n        ])\n\n        cp = CutPasteUnion()\n\n        aug_final = transforms.RandomChoice( [\n            transforms.Lambda(lambda img: aug_crop(img)),\n        ])\n\n\n        for epoch in tqdm(range(epochs)):\n            train_losses = []\n            correct = 0\n            for batch_idx, (images, targets) in enumerate(self.train_loader):\n                if self.args.debug and batch_idx > 3:\n                    break\n                optimizer.zero_grad()\n\n                B,C,H,W = images.shape\n                \n                images, targets = images.to(device), targets.to(device)\n                # y_gen = torch.full((B,), num_class-1, dtype=torch.long, device=device)\n\n                # x_gen11 = [aug_final(img.cpu()) for img in images]\n                # x_gen11 = torch.stack(x_gen11).to(device)\n\n                # adv_data = attack.perturb(x_gen11, y_gen)\n               \n                optimizer.zero_grad()\n                # combined_batch = torch.cat([images, x_gen11, adv_data], dim=0)\n                # combined_batch = torch.cat([images, x_gen11], dim=0)\n\n                # combined_out, combined_mid = model(combined_batch, True)\n                # out, mid = combined_out[:B], combined_mid[:B]\n                # out_gen11 = combined_out[B:]\n                # out_gen11 = combined_out[B:2*B]\n                # out_adv = combined_out[2*B:]\n                out, mid = model(images, True)\n                \n                # one_hot = torch.zeros(B, num_class, device=device)\n                # one_hot.scatter_(1, targets.reshape(-1, 1), 1)\n                # out_second = out - one_hot * 10000\n\n                # ind = torch.randperm(targets.size(0), device=device)\n                # y_mask = torch.where(targets == targets[ind], targets, torch.tensor(10, device=device))\n\n                # phi=torch.distributions.beta.Beta(1, 1).sample([]).item()\n                # mixed_embeddings = phi * mid + (1-phi) * mid[ind]\n                # mixed_out = model.classifier(mixed_embeddings.to(device)) \n\n                \n                # alpha = 1\n                # beta = 1\n                # gamma=0.01\n                # delta=1\n                # alpha = 1\n                # beta = 1\n                # gamma=0.01\n                # delta=1\n                def anneal(start, end, epoch, total):\n                    return start - (start - end) * (min(epoch, total) / total)\n                \n                alpha = anneal(1.0, 0.1, epoch, epochs)  \n                # delta = anneal(1.0, 0.1, epoch, epochs)  \n                delta = 0.0\n             \n                beta = 1 \n                gamma = 0.01\n           \n                loss = criterion(out, targets) #+ alpha*criterion(out_gen11, y_gen) + beta*criterion(out_second, y_gen) + gamma*criterion(mixed_out, y_mask)# + delta*criterion(out_adv, y_gen)\n                 \n\n                pred = torch.max(out, 1)[1]\n                correct += pred.eq(targets.view_as(pred)).sum().item()\n\n                # if self.args.fedexnn_adapter_constrain_beta > 0:\n                #     adapter = model.get_last_training_adapter()\n                #     if adapter is not None:\n                #         balance_loss = conv_balance_regularization(adapter.weight, self.args.fedexnn_adapter_constrain_beta)\n                #         loss += balance_loss\n\n                loss.backward()\n                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n                optimizer.step()\n                train_losses.append(loss.item())\n    \n            train_pfl_acc = 100. * correct / len(self.train_loader.dataset)\n            avg_train_loss = np.mean(train_losses)\n            logging.info(f\"client_id:{client_id} epoch:[{epoch}/{epochs}] loss:{loss}, train_loss:{avg_train_loss} train_pfl_acc: {train_pfl_acc}\")\n            if if_test:\n                acc, test_loss = test(model, self.global_test_loader, device)\n                pfl_acc, pfl_test_loss = test(model, self.test_loader, device)\n            else:\n                acc = 0.0\n                pfl_acc = 0.0\n        model.to(\"cpu\")\n        return model.state_dict(), avg_train_loss, acc, pfl_acc, train_pfl_acc\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T20:04:17.869978Z","iopub.execute_input":"2025-12-27T20:04:17.870555Z","iopub.status.idle":"2025-12-27T20:04:17.879563Z","shell.execute_reply.started":"2025-12-27T20:04:17.870525Z","shell.execute_reply":"2025-12-27T20:04:17.878762Z"}},"outputs":[{"name":"stdout","text":"Overwriting locals/fl_expandable.py\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"%%writefile locals/attack.py\n\nimport os\nimport numpy as np\n\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\n\n#from utils import tensor2cuda\n\ndef project(x, original_x, epsilon, _type='linf'):\n\n    if _type == 'linf':\n        max_x = original_x + epsilon\n        min_x = original_x - epsilon\n\n        x = torch.max(torch.min(x, max_x), min_x)\n\n    elif _type == 'l2':\n        dist = (x - original_x)\n\n        dist = dist.view(x.shape[0], -1)\n\n        dist_norm = torch.norm(dist, dim=1, keepdim=True)\n\n        mask = (dist_norm > epsilon).unsqueeze(2).unsqueeze(3)\n\n        # dist = F.normalize(dist, p=2, dim=1)\n\n        dist = dist / dist_norm\n\n        dist *= epsilon\n\n        dist = dist.view(x.shape)\n\n        x = (original_x + dist) * mask.float() + x * (1 - mask.float())\n\n    else:\n        raise NotImplementedError\n\n    return x\n\nclass FastGradientSignUntargeted():\n    b\"\"\"\n        Fast gradient sign untargeted adversarial attack, minimizes the initial class activation\n        with iterative grad sign updates\n    \"\"\"\n    def __init__(self, model, epsilon, alpha, min_val, max_val, max_iters, device='cpu', _type='linf'):\n        self.model = model\n        self.epsilon = epsilon\n        self.alpha = alpha\n        self.min_val = min_val\n        self.max_val = max_val\n        self.max_iters = max_iters\n        self._type = _type\n        self.device = device\n        \n    def perturb(self, original_images, labels, reduction4loss='mean', random_start=False):\n        # original_images: values are within self.min_val and self.max_val\n\n        # The adversaries created from random close points to the original data\n        '''\n        if random_start:\n            rand_perturb = torch.FloatTensor(original_images.shape).uniform_(\n                -self.epsilon, self.epsilon)\n            rand_perturb = tensor2cuda(rand_perturb)\n            x = original_images + rand_perturb\n            x.clamp_(self.min_val, self.max_val)\n        else:\n        '''\n\n        x = original_images.to(self.device)\n\n        x.requires_grad = True \n\n        # max_x = original_images + self.epsilon\n        # min_x = original_images - self.epsilon\n\n        with torch.enable_grad():\n            for _iter in range(self.max_iters):\n                outputs = self.model(x)#there was a bug over here\n\n                loss = F.cross_entropy(outputs, labels).to(self.device)\n\n                #if reduction4loss == 'none':\n                #    grad_outputs = tensor2cuda(torch.ones(loss.shape))\n                    \n                #else:\n                grad_outputs = None\n\n                grads = torch.autograd.grad(loss, x, grad_outputs=grad_outputs, \n                        only_inputs=True)[0]\n\n                x.data += self.alpha * torch.sign(grads.data) \n\n                # the adversaries' pixel value should within max_x and min_x due \n                # to the l_infinity / l2 restriction\n                x = project(x, original_images, self.epsilon, self._type)\n                # the adversaries' value should be valid pixel value\n                # x.clamp_(self.min_val, self.max_val)\n\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T20:04:19.380163Z","iopub.execute_input":"2025-12-27T20:04:19.380702Z","iopub.status.idle":"2025-12-27T20:04:19.385930Z","shell.execute_reply.started":"2025-12-27T20:04:19.380676Z","shell.execute_reply":"2025-12-27T20:04:19.385314Z"}},"outputs":[{"name":"stdout","text":"Overwriting locals/attack.py\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"%%writefile locals/ccvr.py\nimport logging\n\nimport torch\nimport numpy as np\nfrom torch.utils.data import Dataset, DataLoader\n\n\ndef compute_classes_mean_cov(global_model, models, dataloaders, num_classes, device):\n    features_means, features_covs, features_count = [], [], []\n    for client_idx in dataloaders.keys():\n        if global_model is None:\n            means, covs, sizes = get_means_covs_from_client(\n                models[client_idx], dataloaders[client_idx], device, num_classes\n            )\n        else:\n            means, covs, sizes = get_means_covs_from_client(\n                global_model, dataloaders[client_idx], device, num_classes\n            )\n\n        features_means.append(means)\n        features_covs.append(covs)\n        features_count.append(sizes)\n\n    num_classes = len(features_count[0])-1#to account for unknown class only change\n    labels_count = [sum(cnts) for cnts in zip(*features_count)]\n    classes_mean = []\n    for c, (means, sizes) in enumerate(\n        zip(zip(*features_means), zip(*features_count))\n    ):\n        weights = torch.tensor(sizes, device=device) / labels_count[c]\n        means_ = torch.stack(means, dim=-1)\n        classes_mean.append(torch.sum(means_ * weights, dim=-1))\n    classes_cov = [None for _ in range(num_classes)]\n    for c in range(num_classes):\n        # for k in self.train_clients:\n        for client_idx in dataloaders.keys():\n            if classes_cov[c] is None:\n                classes_cov[c] = torch.zeros_like(features_covs[client_idx][c])\n\n            classes_cov[c] += (features_count[client_idx][c] - 1) / (\n                labels_count[c] - 1\n            ) * features_covs[client_idx][c] + (\n                features_count[client_idx][c] / (labels_count[c] - 1)\n            ) * (\n                features_means[client_idx][c].unsqueeze(1)\n                @ features_means[client_idx][c].unsqueeze(0)\n            )\n\n        classes_cov[c] -= (labels_count[c] / labels_count[c] - 1) * (\n            classes_mean[c].unsqueeze(1) @ classes_mean[c].unsqueeze(0)\n        )\n\n    return classes_mean, classes_cov\n\ndef generate_virtual_representation(\n    classes_mean, classes_cov, sample_per_class, device\n):\n    data, targets = [], []\n    for c, (mean, cov) in enumerate(zip(classes_mean, classes_cov)):\n        samples = np.random.multivariate_normal(\n            mean.cpu().numpy(), cov.cpu().numpy(), sample_per_class\n        )\n        data.append(torch.tensor(samples, dtype=torch.float, device=device))\n        targets.append(\n            torch.ones(\n                sample_per_class, dtype=torch.long, device=device\n            )\n            * c\n        )\n\n    data = torch.cat(data)\n    targets = torch.cat(targets)\n    return data, targets\n\ndef calibrate_classifier(global_model, models, dataloaders, num_classes, sample_per_class, local_lr, device):\n    classes_mean, classes_cov = compute_classes_mean_cov(global_model, models, dataloaders, num_classes, device)\n    data, targets = generate_virtual_representation(classes_mean, classes_cov, sample_per_class, device)\n\n    class RepresentationDataset(Dataset):\n        def __init__(self, data, targets):\n            self.data = data\n            self.targets = targets\n\n        def __getitem__(self, idx):\n            return self.data[idx], self.targets[idx]\n\n        def __len__(self):\n            return len(self.targets)\n\n    dataset = RepresentationDataset(data, targets)\n    dataloader = DataLoader(dataset, batch_size=128, shuffle=True)\n    criterion = torch.nn.CrossEntropyLoss()\n    optimizer = torch.optim.SGD(global_model.parameters(), lr=local_lr)\n\n    for x, y in dataloader:\n        logits = global_model.classifier(x)\n        loss = criterion(logits, y)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n\n\n\ndef get_means_covs_from_client(\n    model, dataloader, device, num_classes\n):\n    features = []\n    targets = []\n    feature_length = None\n    for x, y in dataloader:\n        x, y = x.to(device), y.to(device)\n        features.append(model.get_final_features(x))\n        targets.append(y)\n        # features.append(model.get_final_features(x).to(\"cpu\"))\n        # targets.append(y.to(\"cpu\"))\n        # logging.info(f\"features shape: {features[-1].shape}\")\n\n    targets = torch.cat(targets)\n    features = torch.cat(features)\n    feature_length = features.shape[-1]\n    # indices = [\n    #     torch.where(targets == i)[0]\n    #     for i in range(len(num_classes))\n    # ]\n    indices = [\n        torch.where(targets == i)[0]\n        for i in range(num_classes)\n    ]\n    classes_features = [features[idxs] for idxs in indices]\n    classes_means, classes_covs = [], []\n    for fea in classes_features:\n        if fea.shape[0] > 0:\n            classes_means.append(fea.mean(dim=0))\n            # classes_covs.append(fea.t().cov(correction=0))\n            classes_covs.append(torch.cov(fea.t(), correction=0, fweights=None, aweights=None))\n        else:\n            classes_means.append(torch.zeros(feature_length, device=device))\n            classes_covs.append(\n                torch.zeros(feature_length, feature_length, device=device)\n            )\n    return classes_means, classes_covs, [len(idxs) for idxs in indices]\n","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-12-27T20:04:19.541932Z","iopub.execute_input":"2025-12-27T20:04:19.542448Z","iopub.status.idle":"2025-12-27T20:04:19.548408Z","shell.execute_reply.started":"2025-12-27T20:04:19.542426Z","shell.execute_reply":"2025-12-27T20:04:19.547685Z"}},"outputs":[{"name":"stdout","text":"Overwriting locals/ccvr.py\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"%%writefile models/fl_exnn.py\nfrom copy import deepcopy\nimport logging\nlogger = logging.getLogger()\n\nimport torch\nimport torch.nn.functional as F\nfrom torch import nn\n\nfrom .resnet import norm2d, BasicBlock, Bottleneck\n\n\nclass MLP_Block(nn.Module):\n    def __init__(self, in_features, hidden_features, out_features, actv=\"relu\", num_layers=2):\n        super().__init__()\n        self.in_features = in_features\n        self.hidden_features = hidden_features\n        self.out_features = out_features\n        self.layers = nn.ModuleList()\n        self.num_layers = num_layers\n        layer = nn.Linear(in_features, hidden_features)\n        self.layers.append(layer)\n        for _ in range(self.num_layers - 1):\n            layer = nn.Linear(hidden_features, hidden_features)\n            self.layers.append(layer)\n\n\n    def forward(self, x):\n        for lay in self.layers:\n            x = F.relu(lay(x))\n        return x\n\n\nclass CNN_Block(nn.Module):\n    def __init__(self, in_features, hidden_features, is_pool, actv=\"relu\"):\n        super().__init__()\n        self.in_features = in_features\n        self.hidden_features = hidden_features\n        # self.out_features = out_features\n        self.is_pool = is_pool\n        self.layers = nn.ModuleList()\n        # self.num_layers = num_layers\n        # layer = nn.Linear(in_features, hidden_features)\n        # self.layers.append(layer)\n        # for _ in range(self.num_layers - 1):\n        #     layer = nn.Linear(hidden_features, hidden_features)\n        #     self.layers.append(layer)\n        if self.is_pool:\n            self.layer = nn.Sequential(\n                nn.Conv2d(in_features, hidden_features, 3),\n                nn.BatchNorm2d(hidden_features),\n                nn.ReLU(),\n                nn.MaxPool2d(2, 2))\n        else:\n            self.layer = nn.Sequential(\n                nn.Conv2d(in_features, hidden_features, 3),\n                nn.BatchNorm2d(hidden_features),\n                nn.ReLU())\n\n    def forward(self, x):\n        x = self.layer(x)\n        return x\n\n\n\ndef define_fl_exnn_res_layers(\n    fedexnn_split_num, block, num_blocks, group_norm=0, res_base_width=64, in_channels=3,\n):\n    in_planes = res_base_width\n    group_norm = group_norm\n    # in_planes = in_planes * block.expansion\n\n    def _make_layer(block, planes, num_blocks, stride, group_norm):\n        strides = [stride] + [1] * (num_blocks - 1)\n        layers = []\n        nonlocal in_planes\n        for stride in strides:\n            layers.append(block(in_planes=in_planes, planes=planes,\n                stride=stride, group_norm=group_norm,\n            ))\n            in_planes = planes * block.expansion\n\n        return layers\n\n    if fedexnn_split_num == 2:\n        all_layers = []\n        local_layer = nn.Sequential(\n            nn.Sequential(\n                nn.Conv2d(in_channels, res_base_width, kernel_size=3, stride=1, padding=1, bias=False),\n                nn.BatchNorm2d(res_base_width, group_norm),\n                nn.ReLU(),\n            ),\n            nn.Sequential(*_make_layer(block, res_base_width, num_blocks[0], stride=1, group_norm=group_norm)),\n            nn.Sequential(*_make_layer(block, res_base_width*2, num_blocks[1], stride=2, group_norm=group_norm)),\n        )\n        all_layers.append(local_layer)\n\n        local_layer = nn.Sequential(\n            nn.Sequential(*_make_layer(block, res_base_width*4, num_blocks[2], stride=2, group_norm=group_norm)),\n            nn.Sequential(*_make_layer(block, res_base_width*8, num_blocks[3], stride=2, group_norm=group_norm)),\n            nn.AdaptiveAvgPool2d((1, 1)),\n        )\n        all_layers.append(local_layer)\n    elif fedexnn_split_num == 3:\n        all_layers = []\n        local_layer = nn.Sequential(\n            nn.Conv2d(in_channels, res_base_width, kernel_size=3, stride=1, padding=1, bias=False),\n            nn.BatchNorm2d(res_base_width, group_norm),\n            nn.ReLU(),\n        )\n        all_layers.append(local_layer)\n\n        local_layer = nn.Sequential(\n            nn.Sequential(*_make_layer(block, res_base_width, num_blocks[0], stride=1, group_norm=group_norm)),\n            nn.Sequential(*_make_layer(block, res_base_width*2, num_blocks[1], stride=2, group_norm=group_norm)),\n        )\n        all_layers.append(local_layer)\n\n        local_layer = nn.Sequential(\n            nn.Sequential(*_make_layer(block, res_base_width*4, num_blocks[2], stride=2, group_norm=group_norm)),\n            nn.Sequential(*_make_layer(block, res_base_width*8, num_blocks[3], stride=2, group_norm=group_norm)),\n            nn.AdaptiveAvgPool2d((1, 1)),\n        )\n        all_layers.append(local_layer)\n    elif fedexnn_split_num == 4:\n        all_layers = []\n        local_layer = nn.Sequential(\n            nn.Conv2d(in_channels, res_base_width, kernel_size=3, stride=1, padding=1, bias=False),\n            nn.BatchNorm2d(res_base_width, group_norm),\n            nn.ReLU(),\n        )\n        all_layers.append(local_layer)\n\n        local_layer = nn.Sequential(\n            nn.Sequential(*_make_layer(block, res_base_width, num_blocks[0], stride=1, group_norm=group_norm)),\n            nn.Sequential(*_make_layer(block, res_base_width*2, num_blocks[1], stride=2, group_norm=group_norm)),\n        )\n        all_layers.append(local_layer)\n        all_layers.append(nn.Sequential(*_make_layer(block, res_base_width*4, num_blocks[2], stride=2, group_norm=group_norm)))\n        local_layer = nn.Sequential(\n            nn.Sequential(*_make_layer(block, res_base_width*8, num_blocks[3], stride=2, group_norm=group_norm)),\n            nn.AdaptiveAvgPool2d((1, 1)),\n        )\n        all_layers.append(local_layer)\n    elif fedexnn_split_num == 5:\n        all_layers = []\n        local_layer = nn.Sequential(\n            nn.Conv2d(in_channels, res_base_width, kernel_size=3, stride=1, padding=1, bias=False),\n            nn.BatchNorm2d(res_base_width, group_norm),\n            nn.ReLU(),\n        )\n        all_layers.append(local_layer)\n        all_layers.append(nn.Sequential(*_make_layer(block, res_base_width, num_blocks[0], stride=1, group_norm=group_norm)))\n        all_layers.append(nn.Sequential(*_make_layer(block, res_base_width*2, num_blocks[1], stride=2, group_norm=group_norm)))\n        all_layers.append(nn.Sequential(*_make_layer(block, res_base_width*4, num_blocks[2], stride=2, group_norm=group_norm)))\n        local_layer = nn.Sequential(\n            nn.Sequential(*_make_layer(block, res_base_width*8, num_blocks[3], stride=2, group_norm=group_norm)),\n            nn.AdaptiveAvgPool2d((1, 1)),\n        )\n        all_layers.append(local_layer)\n    elif fedexnn_split_num > 6:\n        all_layers = []\n        local_layer = nn.Sequential(\n            nn.Conv2d(in_channels, res_base_width, kernel_size=3, stride=1, padding=1, bias=False),\n            nn.BatchNorm2d(res_base_width, group_norm),\n            nn.ReLU(),\n        )\n        all_layers.append(local_layer)\n        all_layers.append(nn.Sequential(*_make_layer(block, res_base_width, num_blocks[0], stride=1, group_norm=group_norm)))\n        all_layers.append(nn.Sequential(*_make_layer(block, res_base_width*2, num_blocks[1], stride=2, group_norm=group_norm)))\n        all_layers.append(nn.Sequential(*_make_layer(block, res_base_width*4, num_blocks[2], stride=2, group_norm=group_norm)))\n        local_layer = nn.Sequential(\n            nn.Sequential(*_make_layer(block, res_base_width*8, num_blocks[3], stride=2, group_norm=group_norm)),\n            nn.AdaptiveAvgPool2d((1, 1)),\n        )\n        all_layers.append(local_layer)\n    else:\n        raise NotImplementedError\n    return all_layers\n\n\n\ndef define_fl_exnn_res_layers(\n    block, num_blocks, group_norm=0, res_base_width=64, in_channels=3,\n    hetero_layer_depth=False,\n):\n    in_planes = res_base_width\n    group_norm = group_norm\n    # in_planes = in_planes * block.expansion\n    layers = []\n    def _make_layer(block, planes, num_blocks, stride):\n        nonlocal in_planes\n        nonlocal layers\n        strides = [stride] + [1] * (num_blocks - 1)\n        for stride in strides:\n            layers.append(block(in_planes, planes, stride))\n            in_planes = planes * block.expansion\n\n    layers.append(\n        nn.Sequential(nn.Conv2d(in_channels, res_base_width, kernel_size=3, stride=1, padding=1, bias=False),\n                    norm2d(res_base_width, group_norm),\n                    nn.ReLU())\n            )\n    _make_layer(block, res_base_width, num_blocks[0], stride=1)\n    _make_layer(block, res_base_width*2, num_blocks[1], stride=2)\n    _make_layer(block, res_base_width*4, num_blocks[2], stride=2)\n    _make_layer(block, res_base_width*8, num_blocks[3], stride=2)\n    layers.append(nn.AdaptiveAvgPool2d((1, 1)))\n    if hetero_layer_depth:\n        normal_layers = deepcopy(layers)\n        layers = []\n        layers.append(\n            nn.Sequential(nn.Conv2d(in_channels, res_base_width, kernel_size=3, stride=1, padding=1, bias=False),\n                        norm2d(res_base_width, group_norm),\n                        nn.ReLU())\n                )\n        _make_layer(block, res_base_width, num_blocks[0]-1, stride=1)\n        _make_layer(block, res_base_width*2, num_blocks[1]-1, stride=2)\n        _make_layer(block, res_base_width*4, num_blocks[2]-1, stride=2)\n        _make_layer(block, res_base_width*8, num_blocks[3]-1, stride=2)\n        layers.append(nn.AdaptiveAvgPool2d((1, 1)))\n        small_layers = deepcopy(layers)\n        layers = []\n        layers.append(\n            nn.Sequential(nn.Conv2d(in_channels, res_base_width, kernel_size=3, stride=1, padding=1, bias=False),\n                        norm2d(res_base_width, group_norm),\n                        nn.ReLU())\n                )\n        _make_layer(block, res_base_width, num_blocks[0]+1, stride=1)\n        _make_layer(block, res_base_width*2, num_blocks[1]+1, stride=2)\n        _make_layer(block, res_base_width*4, num_blocks[2]+1, stride=2)\n        _make_layer(block, res_base_width*8, num_blocks[3]+1, stride=2)\n        layers.append(nn.AdaptiveAvgPool2d((1, 1)))\n        large_layers = deepcopy(layers)\n    else:\n        small_layers, large_layers = None, None\n    return layers, small_layers, large_layers\n\n\n\ndef fl_exnn_resnet18(**kwargs):\n    return define_fl_exnn_res_layers( \n                BasicBlock, [2, 2, 2, 2], **kwargs)\n\n\ndef fl_exnn_resnet34(**kwargs):\n    return define_fl_exnn_res_layers(\n                BasicBlock, [3, 4, 6, 3], **kwargs)\n\n\ndef fl_exnn_resnet50(**kwargs):\n    return define_fl_exnn_res_layers(\n                Bottleneck, [3, 4, 6, 3], **kwargs)\n\n\ndef fl_exnn_resnet101(**kwargs):\n    return define_fl_exnn_res_layers(\n                Bottleneck, [3, 4, 23, 3], **kwargs)\n\n\ndef fl_exnn_resnet152(**kwargs):\n    return define_fl_exnn_res_layers(\n                Bottleneck, [3, 8, 36, 3], **kwargs)\n\n\nclass AttentionAdapter(nn.Module):\n    def __init__(self, in_channels, out_channels, reduction=16):\n        super(AttentionAdapter, self).__init__()\n        self.align = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n        self.bn = nn.BatchNorm2d(out_channels)\n        \n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.channel_fc = nn.Sequential(\n            nn.Linear(out_channels, out_channels // reduction, bias=False),\n            nn.ReLU(inplace=True),\n            nn.Linear(out_channels // reduction, out_channels, bias=False),\n            nn.Sigmoid()\n        )#added a more comlex adaptor\n\n    def forward(self, x):\n        x = self.bn(self.align(x))\n        b, c, _, _ = x.size()\n        y = self.avg_pool(x).view(b, c)\n        y = self.channel_fc(y).view(b, c, 1, 1)\n     \n        return x * y.expand_as(x)\n\n\nclass Federated_EXNNLayer_local(nn.Module):\n\n    def __init__(self, layer_idx,\n                local_layer,\n                client_idx=0,\n                adapter=\"avg\", \n                fedexnn_self_dropout=0.0\n            ):\n        super().__init__()\n        self.layer_idx = layer_idx\n        self.is_global = False\n        self.local_layer = local_layer\n        self.client_idx = client_idx\n        # self.in_features = local_layer.in_features\n        self.adapter = adapter\n        self.fedexnn_self_dropout = fedexnn_self_dropout\n        if self.fedexnn_self_dropout > 0:\n            self.dropout = nn.Dropout(p=self.fedexnn_self_dropout)\n\n\n    def adaptation(self, in_channels=1, out_channels=1):\n        if self.adapter in [\"avg\", \"sum\"]:\n            pass\n        elif self.adapter == \"cnn1x1\":\n            # self.adapter_nn = nn.Conv2d(\n            #     in_channels=in_channels,\n            #     out_channels=out_channels, kernel_size=1, stride=1, padding=0)\n            self.adapter_nn = AttentionAdapter(in_channels, out_channels)\n        elif self.adapter == \"mlp\":\n            raise NotImplementedError\n        else:\n            raise NotImplementedError\n\n    def get_module(self):\n        return self.local_layer\n\n    def forward(self, x, is_global):\n        if is_global:\n            if self.fedexnn_self_dropout > 0:\n                x[str(self.client_idx)] = self.dropout(x[str(self.client_idx)])\n            if self.adapter == \"avg\":\n                xs = list(x.values())\n                x = sum(xs) / len(xs)\n            elif self.adapter == \"sum\":\n                x = sum(list(x.values()))\n            elif self.adapter == \"cnn1x1\":\n                # x = self.adapter_layers[str(i)](  torch.concat(list(x.values()), dim=1) )\n                x = self.adapter_nn(torch.concat(list(x.values()), dim=1))\n\n            elif self.adapter == \"mlp\":\n                raise NotImplementedError\n            else:\n                raise NotImplementedError\n        else:\n            if self.fedexnn_self_dropout > 0:\n                x = self.dropout(x)\n        return self.local_layer(x)\n\n\nclass Federated_EXNNLayer_global(nn.Module):\n\n    def __init__(self, layer_idx,\n                local_layers, fedexnn_self_dropout=0.0\n            ):\n        super().__init__()\n        self.layer_idx = layer_idx\n        self.is_global = True\n        self.fedexnn_self_dropout = fedexnn_self_dropout\n\n        self.local_layers = torch.nn.ModuleDict()\n        for client_idx, local_layer in local_layers.items():\n            self.local_layers[client_idx] = local_layer\n\n        # logger.info(f\"list(local_layers.values())[0]: {list(local_layers.values())[0]}\")\n\n        # if hasattr(list(local_layers.values())[0], \"in_features\"):\n        #     self.in_features = list(local_layers.values())[0].in_features\n        # else:\n        #     pass\n\n    def get_module(self):\n        return self.local_layers\n\n    def freeze(self):\n        for client_idx, local_layer in self.local_layers.items():\n            for param in local_layer.parameters():\n                param.requires_grad = False\n\n\n    def forward(self, x, is_global):\n        xs = {}\n        for client_idx, local_layer in self.local_layers.items():\n            xs[client_idx] = local_layer(x, is_global)\n        return xs\n\n\n# def merge_layer(Federated_EXNNs, layer_idx):\n#     horizon_layers = {}\n#     # for client_idx, Federated_EXNN in enumerate(Federated_EXNNs):\n#     for client_idx, Federated_EXNN in Federated_EXNNs.items():\n#         logger.info(f\"Merging layer {layer_idx}, model has num of layers:{len(Federated_EXNN.layers)}\")\n#         horizon_layers[client_idx] = Federated_EXNN.layers[layer_idx].get_module()\n#     federated_EXNNLayer_global = Federated_EXNNLayer_global(layer_idx, horizon_layers)\n#     return federated_EXNNLayer_global\n\n\n\ndef merge_layer(Federated_EXNNs, layer_idx):\n    horizon_layers = {}\n    # for client_idx, Federated_EXNN in enumerate(Federated_EXNNs):\n    for client_idx, Federated_EXNN in Federated_EXNNs.items():\n        logger.info(f\"Merging layer {layer_idx}, model has num of layers:{len(Federated_EXNN.layers)}\")\n        horizon_layers[str(client_idx)] = Federated_EXNN.layers[layer_idx]\n    federated_EXNNLayer_global = Federated_EXNNLayer_global(layer_idx, horizon_layers)\n    return federated_EXNNLayer_global\n\n\n\nclass Federated_EXNN(nn.Module):\n    def __init__(\n        self,\n        args,\n        client_idx,\n        split_local_layers=[],\n        num_of_classes=10,\n        fedexnn_classifer=\"avg\",\n    ):\n        super().__init__()\n        self.args = args\n        self.client_idx = client_idx\n        self.num_layers = len(split_local_layers)\n        if args.model == \"cnn\":\n            self.hidden_features = args.cnn_hidden_features * 4 * 4\n            self.flatten_at_classifier = True\n        elif args.model == \"mlp3\":\n            self.hidden_features = args.mlp_hidden_features\n            self.flatten_at_classifier = False\n        elif args.model in [\"resnet18\",]:\n            self.hidden_features = args.res_base_width * 8 * 1\n            self.flatten_at_classifier = True\n        elif args.model in [\"resnet50\", ]:\n            self.hidden_features = args.res_base_width * 8 * 4\n            self.flatten_at_classifier = True\n        else:\n            raise NotImplementedError\n        self.num_of_classes = num_of_classes\n        # self.adapter = adapter\n        # self.adapter_layers = torch.nn.ModuleDict()\n\n        self.layers = nn.ModuleList()\n        for i, local_layer in enumerate(split_local_layers):\n            # lay = Federated_EXNNLayer_local(\n            #     i,\n            #     local_layer,\n            # )\n            # self.layers.append(lay)\n            self.layers.append(local_layer)\n\n        self.classifier = torch.nn.Linear(self.hidden_features, num_of_classes)\n        self.fedexnn_classifer = fedexnn_classifer\n\n    # def adaptation(self, layer_idx, federated_EXNNLayer_global, in_channels=1, out_channels=1):\n    def adaptation(self, layer_idx, federated_EXNNLayer_global):\n        federated_EXNNLayer_global.freeze()\n        del self.layers[layer_idx]\n        self.layers.insert(layer_idx, federated_EXNNLayer_global)\n        # self.layers[layer_idx] = federated_EXNNLayer_global\n\n    def add_local_layer_adaptor(self, layer_idx, **kwargs):\n        assert not self.layers[layer_idx].is_global\n        self.layers[layer_idx].adaptation(**kwargs)\n\n    def get_last_training_adapter(self):\n        for layer_idx, layer in enumerate(self.layers):\n            if not layer.is_global and hasattr(layer, \"adapter_nn\"):\n                return layer.adapter_nn\n        return None\n\n    # def adaptation(self, layer_idx, federated_EXNNLayer_global, in_channels=1, out_channels=1):\n    #     federated_EXNNLayer_global.freeze()\n    #     # self.layers[layer_idx] = federated_EXNNLayer_global\n    #     # self.layers.pop(layer_idx)\n    #     del self.layers[layer_idx]\n    #     self.layers.insert(layer_idx, federated_EXNNLayer_global)\n    #     # self.layers[layer_idx] = federated_EXNNLayer_global\n    #     if layer_idx < self.num_layers - 1:\n    #         if self.adapter in [\"avg\", \"sum\"]:\n    #             pass\n    #         elif self.adapter == \"cnn1x1\":\n    #             self.adapter_layers[str(layer_idx)] = nn.Conv2d(\n    #                 in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=1, padding=0)\n    #         elif self.adapter == \"mlp\":\n    #             raise NotImplementedError\n    #         else:\n    #             raise NotImplementedError\n    #     else:\n    #         pass\n\n\n    def adaptation_classifier(self, fedexnn_classifer, new_classifier=None):\n        self.fedexnn_classifer = fedexnn_classifer\n        self.classifier = new_classifier\n\n\n    def forward(self, x, get_logits=False):\n        # x = x.contiguous()\n        # if self.flatten_at_classifier:\n        #     pass\n        # else:\n        #     x = x.contiguous()\n        #     x = x.view(x.size(0), self.layers[0].in_features)\n        #     # logger.info(f\"type(x): {type(x)}\")\n        prev_is_global = False\n        for i, lay in enumerate(self.layers):\n            # first layer is raw data, no need to adapt\n            x = lay(x, prev_is_global)\n            prev_is_global = lay.is_global\n            # if getattr(lay, \"is_global\", False) and i < self.num_layers - 1:\n\n        logits = None\n        if getattr(self.layers[-1], \"is_global\", False):\n            if self.flatten_at_classifier:\n                for k, v in x.items():\n                    x[k] = v.view(v.size(0), -1)\n            else:\n                pass\n            if self.fedexnn_classifer in [\"avg\"] :\n                x = sum(list(x.values()))\n                if get_logits:\n                    logits = x\n                outputs = self.classifier(x)\n            elif self.fedexnn_classifer == \"multihead\":\n                outputs = self.classifier(x)\n                outputs = sum(x)\n            else:\n                raise NotImplementedError\n        else:\n            if self.flatten_at_classifier:\n                x = x.view(x.size(0), -1)\n                if get_logits:\n                    logits = x\n            else:\n                pass\n            outputs = self.classifier(x)\n        if get_logits:\n            return outputs, logits\n        else:\n            return outputs\n\n\n\n    def forward_measure(self, x):\n        hidden_xs = {}\n        # for layer_index, module in enumerate(self._layers.values()):\n        # for layer_index, module in enumerate(self._layers):\n        prev_is_global = False\n        for i, lay in enumerate(self.layers):\n            x = lay(x, prev_is_global)\n            prev_is_global = lay.is_global\n            # The outputed x is globally, thus average it for measuring MI. \n            xs = list(x.values())\n            x_avg = sum(xs) / len(xs)\n            x_avg = x_avg.detach()\n            hidden_xs[i] = x_avg\n        current_i = i\n\n        if getattr(self.layers[-1], \"is_global\", False):\n            if self.flatten_at_classifier:\n                for k, v in x.items():\n                    x[k] = v.view(v.size(0), -1)\n            else:\n                pass\n            if self.fedexnn_classifer in [\"avg\"] :\n                x = sum(list(x.values()))\n                outputs = self.classifier(x)\n            elif self.fedexnn_classifer == \"multihead\":\n                outputs = self.classifier(x)\n                outputs = sum(x)\n            else:\n                raise NotImplementedError\n        else:\n            if self.flatten_at_classifier:\n                x = x.view(x.size(0), -1)\n            else:\n                pass\n            outputs = self.classifier(x)\n        # hidden_xs[current_i+1] = outputs\n        return outputs, hidden_xs\n\n\n\n    def get_final_features(self, x):\n        prev_is_global = False\n        for i, lay in enumerate(self.layers):\n            # first layer is raw data, no need to adapt\n            x = lay(x, prev_is_global)\n            prev_is_global = lay.is_global\n\n\n        if getattr(self.layers[-1], \"is_global\", False):\n            if self.flatten_at_classifier:\n                for k, v in x.items():\n                    x[k] = v.view(v.size(0), -1)\n            else:\n                pass\n            if self.fedexnn_classifer in [\"avg\"] :\n                x = sum(list(x.values()))\n            elif self.fedexnn_classifer == \"multihead\":\n                pass\n            else:\n                raise NotImplementedError\n        else:\n            pass\n\n        return x\n\n","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile models/configs.py\n\nSplit_Configs = {\n    'mlp2': {\n        1: [],  # End-to-end\n        2: [0],\n        3: [0, 1],\n    },\n    'mlp3': {\n        1: [],  # End-to-end\n        2: [1],\n        3: [0, 1],\n        4: [0, 1, 2],\n    },\n    'resnet18': { # 0-base conv, 1-2, 3-4, 5-6, 7-8, 9: Avg-linear\n        1: [],  # End-to-end\n        2: [4],\n        3: [2, 6],\n        4: [2, 4, 6],\n        8: [2, 3, 4, 5, 6, 7, 8],\n    },\n    'resnet34': { # 0-base conv, 1-3, 4-7, 8-13, 14-16, 17: Avg-linear\n        1: [],  # End-to-end\n        2: [8],\n        3: [5, 12],\n        4: [4, 8, 12],\n        8: [2, 4, 6, 8, 10, 12, 14],\n        16: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16],\n    },\n    'resnet50': { # 0-base conv, 1-3, 4-7, 8-13, 14-16, 17: Avg-linear\n        1: [],  # End-to-end\n        2: [8],\n        3: [5, 12],\n        4: [4, 8, 12],\n        8: [2, 4, 6, 8, 10, 12, 14],\n        16: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16],\n    },\n}\n\nEXNN_Split_Configs = {\n    'mlp2': {\n        1: [],  # End-to-end\n        2: [0],\n        3: [0, 1],\n    },\n    'mlp3': {\n        1: [],  # End-to-end\n        2: [1],\n        3: [0, 1],\n        4: [0, 1, 2],\n    },\n    'cnn': {\n        1: [],  # End-to-end\n        2: [1],\n        3: [0, 1],\n        4: [0, 1, 2],#cnn config\n    },\n    'resnet18': { # 0-base conv, 1-2, 3-4, 5-6, 7-8, 9: Avg-linear\n        1: [],  # End-to-end\n        2: [4],\n        3: [0, 4],\n        4: [0, 4, 6],\n        8: [0, 1, 2, 3, 5, 7, 8],\n    },\n}\n\n\nInfoPro = {\n    'mlp2': {\n        1: [],  # End-to-end\n        2: [0],\n        3: [0, 1],\n    },\n    'mlp3': {\n        1: [],  # End-to-end\n        2: [1],\n        3: [0, 1],\n        4: [0, 1, 2],\n    },\n    'resnet18': { # 0-base conv, 1-2, 3-4, 5-6, 7-8, 9: Avg-linear\n        1: [],  # End-to-end\n        2: [4],\n        3: [2, 6],\n        4: [2, 4, 6],\n        8: [2, 3, 4, 5, 6, 7, 8],\n    },\n    'resnet34': { # 0-base conv, 1-3, 4-7, 8-13, 14-16, 17: Avg-linear\n        1: [],  # End-to-end\n        2: [8],\n        3: [5, 12],\n        4: [4, 8, 12],\n        8: [2, 4, 6, 8, 10, 12, 14],\n        16: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16],\n    },\n    'resnet50': { # 0-base conv, 1-3, 4-7, 8-13, 14-16, 17: Avg-linear\n        1: [],  # End-to-end\n        2: [8],\n        3: [5, 12],\n        4: [4, 8, 12],\n        8: [2, 4, 6, 8, 10, 12, 14],\n        16: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16],\n    },\n}\n\n\nInfoPro_balanced_memory = {\n    'mlp2': {\n        1: [],  # End-to-end\n        2: [0],\n        3: [0, 1],\n    },\n    'mlp3': {\n        1: [],  # End-to-end\n        2: [1],\n        3: [0, 1],\n        4: [0, 1, 2],\n    },\n    'resnet18': { # 0-base conv, 1-2, 3-4, 5-6, 7-8, 9: Avg-linear\n        1: [],  # End-to-end\n        2: [4],\n        3: [2, 6],\n        4: [2, 4, 6],\n        8: [2, 3, 4, 5, 6, 7, 8],\n    },\n    'resnet34': { # 0-base conv, 1-3, 4-7, 8-13, 14-16, 17: Avg-linear\n        1: [],  # End-to-end\n        2: [8],\n        3: [5, 12],\n        4: [4, 8, 12],\n        8: [2, 4, 6, 8, 10, 12, 14],\n        16: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16],\n    },\n    'resnet50': { # 0-base conv, 1-3, 4-7, 8-13, 14-16, 17: Avg-linear\n        1: [],  # End-to-end\n        2: [8],\n        3: [5, 12],\n        4: [4, 8, 12],\n        8: [2, 4, 6, 8, 10, 12, 14],\n        16: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16],\n    },\n}","metadata":{"trusted":true,"jupyter":{"source_hidden":true,"outputs_hidden":true},"execution":{"iopub.status.busy":"2025-12-27T20:04:20.117760Z","iopub.execute_input":"2025-12-27T20:04:20.118393Z","iopub.status.idle":"2025-12-27T20:04:20.123479Z","shell.execute_reply.started":"2025-12-27T20:04:20.118369Z","shell.execute_reply":"2025-12-27T20:04:20.122854Z"},"collapsed":true},"outputs":[{"name":"stdout","text":"Overwriting models/configs.py\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"%%writefile models/nets.py\n\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\n\nfrom .basics import View\n\n\nclass CNNMnist(nn.Module):\n    def __init__(self):\n        super(CNNMnist, self).__init__()\n        self.layer1 = nn.Sequential(\n            nn.Conv2d(1, 16, kernel_size=5, padding=2),\n            nn.BatchNorm2d(16),\n            nn.ReLU(),\n            nn.MaxPool2d(2))\n        self.layer2 = nn.Sequential(\n            nn.Conv2d(16, 32, kernel_size=5, padding=2),\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.MaxPool2d(2))\n        self.fc = nn.Linear(7 * 7 * 32, 10)\n\n    def forward(self, x):\n        out = self.layer1(x)\n        out = self.layer2(out)\n        out = out.view(out.size(0), -1)\n        out = self.fc(out)\n        return out\n\n\nclass CNNCifar(nn.Module):\n    def __init__(self, hidden_features, num_of_classes):\n        super(CNNCifar, self).__init__()\n        self.hidden_features = hidden_features\n        self.layer1 = nn.Sequential(\n            nn.Conv2d(3, self.hidden_features, 3),\n            nn.BatchNorm2d(self.hidden_features),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2))\n        self.layer2 = nn.Sequential(\n            nn.Conv2d(self.hidden_features, self.hidden_features, 3),\n            nn.BatchNorm2d(self.hidden_features),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2))\n        self.layer3 = nn.Sequential(\n            nn.Conv2d(self.hidden_features, self.hidden_features, 3),\n            nn.BatchNorm2d(self.hidden_features),\n            nn.ReLU())\n        # self.conv1 = nn.Conv2d(3, self.hidden_features, 3)\n        # self.pool = nn.MaxPool2d(2, 2)\n        # self.conv2 = nn.Conv2d(self.hidden_features, self.hidden_features, 3)\n        # self.conv3 = nn.Conv2d(self.hidden_features, self.hidden_features, 3)\n\n        self.fc1 = nn.Linear(self.hidden_features * 4 * 4, num_of_classes)\n\n    def forward(self, x):\n        # x = self.pool(F.relu(self.conv1(x)))\n        # x = self.pool(F.relu(self.conv2(x)))\n        # x = F.relu(self.conv3(x))\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n\n        x = x.view(-1, self.hidden_features * 4 * 4)\n        x = self.fc1(x)\n        return x\n\n\n\nimport torch\nimport torch.nn as nn\n\n\ndef make_CNNCifar_seqs(in_features, hidden_features, out_features, init_classifier):\n    layers = []\n    \n    # Block 1: 32x32 -> 16x16\n    layers.append(nn.Sequential(\n        nn.Conv2d(in_features, hidden_features, kernel_size=3, padding=1),\n        nn.BatchNorm2d(hidden_features),\n        nn.ReLU(),\n        nn.Conv2d(hidden_features, hidden_features, kernel_size=3, padding=1),\n        nn.BatchNorm2d(hidden_features),\n        nn.ReLU(),\n        nn.MaxPool2d(kernel_size=2, stride=2)\n    ))\n#cnns\n    # Block 2: 16x16 -> 8x8\n    layers.append(nn.Sequential(\n        nn.Conv2d(hidden_features, hidden_features * 2, kernel_size=3, padding=1),\n        nn.BatchNorm2d(hidden_features * 2),\n        nn.ReLU(),\n        nn.Conv2d(hidden_features * 2, hidden_features * 2, kernel_size=3, padding=1),\n        nn.BatchNorm2d(hidden_features * 2),\n        nn.ReLU(),\n        nn.MaxPool2d(kernel_size=2, stride=2)\n    ))\n\n    # Block 3: 8x8 -> 4x4\n    layers.append(nn.Sequential(\n        nn.Conv2d(hidden_features * 2, hidden_features * 4, kernel_size=3, padding=1),\n        nn.BatchNorm2d(hidden_features * 4),\n        nn.ReLU(),\n        nn.Conv2d(hidden_features * 4, hidden_features * 4, kernel_size=3, padding=1),\n        nn.BatchNorm2d(hidden_features * 4),\n        nn.ReLU(),\n        nn.MaxPool2d(kernel_size=2, stride=2)\n    ))\n\n    # Block 4: Flattening and the 2048 Linear layer\n    flattened_input_dim = (hidden_features * 4) * 4 * 4\n    layers.append(nn.Sequential(\n        View([flattened_input_dim]), # Flatten FIRST\n        nn.Linear(flattened_input_dim, 2048), # Apply Linear SECOND\n        nn.ReLU(),\n        nn.Dropout(0.5)\n    ))\n\n    if init_classifier:\n        # Final output layer\n        # Since the last layer in the list above is 2048, this starts at 2048\n        classifier = nn.Linear(2048, out_features)\n        layers.append(classifier)\n\n    return layers\n\n\ndef make_CNNCifar_Head_seqs(in_features, hidden_features, out_features, init_classifier, split_layer_index):\n    origin_res_layer_index = 0\n    layers = []\n    if origin_res_layer_index > split_layer_index:\n        layers.append(nn.Sequential(\n            nn.Conv2d(in_features, hidden_features, 3),\n            nn.BatchNorm2d(hidden_features),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2)))\n    origin_res_layer_index += 1\n    if origin_res_layer_index > split_layer_index:\n        layers.append(nn.Sequential(\n            nn.Conv2d(hidden_features, hidden_features, 3),\n            nn.BatchNorm2d(hidden_features),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2)))\n    origin_res_layer_index += 1\n    if origin_res_layer_index > split_layer_index:\n        layers.append(nn.Sequential(\n            nn.Conv2d(hidden_features, hidden_features, 3),\n            nn.BatchNorm2d(hidden_features),\n            nn.ReLU(),\n            View([hidden_features * 4 * 4])))\n    origin_res_layer_index += 1\n\n    if init_classifier:\n        if origin_res_layer_index > split_layer_index:\n            classifier = torch.nn.Linear(hidden_features, out_features)\n            layers.append(classifier)\n        origin_res_layer_index += 1\n    return layers\n\n\n\n\n\nclass CNNCifar100(nn.Module):\n    def __init__(self):\n        super(CNNCifar100, self).__init__()\n        self.conv1 = nn.Conv2d(3, 256, 3)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(256, 256, 3)\n        self.conv3 = nn.Conv2d(256, 128, 3)\n        self.fc1 = nn.Linear(128 * 4 * 4, 100)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = F.relu(self.conv3(x))\n        x = x.view(-1, 128 * 4 * 4)\n        x = self.fc1(x)\n        return x\n\n\nclass CNNCifar2(nn.Module):  # 重新搭建CNN\n    def __init__(self):\n        super(CNNCifar2, self).__init__()\n        self.conv1 = nn.Conv2d(3, 32, 3)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(32, 64, 3)\n        self.conv3 = nn.Conv2d(64, 64, 3)\n        self.fc1 = nn.Linear(64 * 4 * 4, 64)\n        self.fc2 = nn.Linear(64, 10)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = F.relu(self.conv3(x))\n        x = x.view(-1, 64 * 4 * 4)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T20:04:20.365709Z","iopub.execute_input":"2025-12-27T20:04:20.366417Z","iopub.status.idle":"2025-12-27T20:04:20.373044Z","shell.execute_reply.started":"2025-12-27T20:04:20.366388Z","shell.execute_reply":"2025-12-27T20:04:20.372315Z"},"jupyter":{"source_hidden":true}},"outputs":[{"name":"stdout","text":"Overwriting models/nets.py\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"%%bash\n\ncluster_name=localhost\ndataset=cifar10\n\nsource scripts/setup_env.sh\nsource scripts/path.sh\n\ngpu=0\n\ndebug=False\nenable_wandb=True\n\n\n\nnum_users=5\n\n\nalpha=0.5\ncheckpoint=weights\nres_base_width=64\ncheckpoint=no\nfedexnn_adapter=cnn1x1\nfedexnn_split_num=4\nlocal_ep=50\nwandb_entity=cabbagepatch-lahore-university-of-management-sciences\nmodel=resnet18\nnum_classes=11\nlr=0.01\n\n\ntype=fed-expandable\nsource scripts/resetup_env.sh\n\nfedexnn_classifer=${fedexnn_classifer:-avg}\n\npython3 -u main.py --main_task=train --type=$type  --gpu $gpu  --debug $debug \\\n--exp_name ${type}-${dataset}-${model}-nh${num_hidden_features}-c${num_users}-a${alpha}-ep${local_ep}-lr${lr}-clsf${fedexnn_classifer}-adp${fedexnn_adapter}-nxnn${fedexnn_split_num} \\\n--checkpoint $checkpoint  \\\n--split_measure_local_module_num 8 \\\n--fedexnn_classifer  ${fedexnn_classifer} --fedexnn_adapter ${fedexnn_adapter}  --fedexnn_split_num ${fedexnn_split_num} \\\n--fedexnn_self_dropout $fedexnn_self_dropout --fedexnn_adapter_constrain_beta $fedexnn_adapter_constrain_beta \\\n--model=$model --mlp_hidden_features=$mlp_hidden_features --cnn_hidden_features $cnn_hidden_features --num_layers $num_layers --res_base_width $res_base_width \\\n--iid=0 --lr=$lr \\\n--dataset=${dataset} --datadir $datadir \\\n--alpha=$alpha --seed=1 --num_users=${num_users} --local_ep=$local_ep \\\n--wandb_entity ${wandb_entity} --project_name FuseFL --enable_wandb $enable_wandb --wandb_offline False \\\n--wandb_key '80702ded3cdc00fb5532f8f21e2ebabb3d2b1b22' --num_classes=${num_classes}\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T20:04:20.700704Z","iopub.execute_input":"2025-12-27T20:04:20.701413Z","iopub.status.idle":"2025-12-27T20:26:58.167252Z","shell.execute_reply.started":"2025-12-27T20:04:20.701385Z","shell.execute_reply":"2025-12-27T20:26:58.165986Z"}},"outputs":[{"name":"stdout","text":"Process is terminated.\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}